{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merged df has 278 rows and 124 columns. It has columns like ID, stage, gender, date, condition, VVR_group, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Stage</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Faintness</th>\n",
       "      <th>Dizziness</th>\n",
       "      <th>Weakness</th>\n",
       "      <th>Lightheadedness</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_r__standard_deviation</th>\n",
       "      <th>AU26_r__maximum</th>\n",
       "      <th>AU26_r__mean</th>\n",
       "      <th>AU26_r__root_mean_square</th>\n",
       "      <th>AU45_r__sum_values</th>\n",
       "      <th>AU45_r__variance</th>\n",
       "      <th>AU45_r__standard_deviation</th>\n",
       "      <th>AU45_r__maximum</th>\n",
       "      <th>AU45_r__mean</th>\n",
       "      <th>AU45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.585935</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>-0.786613</td>\n",
       "      <td>-0.696839</td>\n",
       "      <td>0.520966</td>\n",
       "      <td>1.700927</td>\n",
       "      <td>1.712210</td>\n",
       "      <td>0.830151</td>\n",
       "      <td>1.741972</td>\n",
       "      <td>1.745418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.624259</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>-0.642748</td>\n",
       "      <td>-0.651193</td>\n",
       "      <td>-0.504468</td>\n",
       "      <td>0.296375</td>\n",
       "      <td>0.440450</td>\n",
       "      <td>0.760722</td>\n",
       "      <td>1.243173</td>\n",
       "      <td>0.665506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.367560</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>3.132948</td>\n",
       "      <td>2.795771</td>\n",
       "      <td>0.129283</td>\n",
       "      <td>-0.279627</td>\n",
       "      <td>-0.201661</td>\n",
       "      <td>0.014352</td>\n",
       "      <td>-0.478731</td>\n",
       "      <td>-0.279724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584439</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.394186</td>\n",
       "      <td>0.499951</td>\n",
       "      <td>-0.587993</td>\n",
       "      <td>0.094357</td>\n",
       "      <td>0.226315</td>\n",
       "      <td>-0.645230</td>\n",
       "      <td>0.514820</td>\n",
       "      <td>0.302852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.517633</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>-0.951628</td>\n",
       "      <td>-0.731221</td>\n",
       "      <td>-1.239117</td>\n",
       "      <td>-0.246984</td>\n",
       "      <td>-0.162414</td>\n",
       "      <td>0.639220</td>\n",
       "      <td>-1.034420</td>\n",
       "      <td>-0.377156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.804403</td>\n",
       "      <td>-0.162826</td>\n",
       "      <td>-0.846163</td>\n",
       "      <td>-0.845794</td>\n",
       "      <td>-0.142084</td>\n",
       "      <td>0.642278</td>\n",
       "      <td>0.784992</td>\n",
       "      <td>0.864866</td>\n",
       "      <td>0.560518</td>\n",
       "      <td>0.737070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-07-11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.926084</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>-1.669019</td>\n",
       "      <td>-1.846330</td>\n",
       "      <td>-0.586609</td>\n",
       "      <td>-0.362405</td>\n",
       "      <td>-0.303044</td>\n",
       "      <td>0.326786</td>\n",
       "      <td>-0.488608</td>\n",
       "      <td>-0.360082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266200</td>\n",
       "      <td>3.521479</td>\n",
       "      <td>0.610696</td>\n",
       "      <td>0.169932</td>\n",
       "      <td>-2.381393</td>\n",
       "      <td>4.280036</td>\n",
       "      <td>3.507346</td>\n",
       "      <td>0.517718</td>\n",
       "      <td>2.061400</td>\n",
       "      <td>3.218211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.889172</td>\n",
       "      <td>-3.328215</td>\n",
       "      <td>-1.706598</td>\n",
       "      <td>-1.845208</td>\n",
       "      <td>-0.958863</td>\n",
       "      <td>-0.594948</td>\n",
       "      <td>-0.603916</td>\n",
       "      <td>-0.315439</td>\n",
       "      <td>-0.770324</td>\n",
       "      <td>-0.661360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>331</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340280</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>-1.779581</td>\n",
       "      <td>0.208143</td>\n",
       "      <td>0.696288</td>\n",
       "      <td>6.381711</td>\n",
       "      <td>4.701091</td>\n",
       "      <td>4.440496</td>\n",
       "      <td>2.616941</td>\n",
       "      <td>4.291136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Stage  Gender        Date  Location  Condition  Faintness  \\\n",
       "0      7    1.0       2  2019-10-28         0          2        1.0   \n",
       "1     23    1.0       2  2020-08-01         1          2        1.0   \n",
       "2     24    1.0       2  2020-01-22         1          2        1.0   \n",
       "3     25    1.0       2  2020-05-02         1          2        1.0   \n",
       "4     26    1.0       1  2020-06-02         2          1        2.0   \n",
       "..   ...    ...     ...         ...       ...        ...        ...   \n",
       "273  323    1.0       2  2022-10-26         3          3        1.0   \n",
       "274  325    1.0       2  2022-07-11         3          3        1.0   \n",
       "275  329    1.0       2  2022-11-28         3          3        1.0   \n",
       "276  330    1.0       2  2022-11-30         0          3        1.0   \n",
       "277  331    1.0       2  2022-11-30         0          3        1.0   \n",
       "\n",
       "     Dizziness  Weakness  Lightheadedness  ...  AU26_r__standard_deviation  \\\n",
       "0          1.0       1.0              2.0  ...                   -0.585935   \n",
       "1          2.0       2.0              1.0  ...                   -0.624259   \n",
       "2          1.0       1.0              1.0  ...                    2.367560   \n",
       "3          1.0       1.0              1.0  ...                    0.584439   \n",
       "4          2.0       2.0              1.0  ...                   -0.517633   \n",
       "..         ...       ...              ...  ...                         ...   \n",
       "273        1.0       1.0              1.0  ...                   -0.804403   \n",
       "274        1.0       1.0              1.0  ...                   -1.926084   \n",
       "275        1.0       1.0              1.0  ...                   -0.266200   \n",
       "276        1.0       1.0              1.0  ...                   -1.889172   \n",
       "277        1.0       1.0              1.0  ...                    1.340280   \n",
       "\n",
       "     AU26_r__maximum  AU26_r__mean  AU26_r__root_mean_square  \\\n",
       "0           0.425279     -0.786613                 -0.696839   \n",
       "1           0.425279     -0.642748                 -0.651193   \n",
       "2           0.425279      3.132948                  2.795771   \n",
       "3           0.425279      0.394186                  0.499951   \n",
       "4           0.425279     -0.951628                 -0.731221   \n",
       "..               ...           ...                       ...   \n",
       "273        -0.162826     -0.846163                 -0.845794   \n",
       "274         0.425279     -1.669019                 -1.846330   \n",
       "275         3.521479      0.610696                  0.169932   \n",
       "276        -3.328215     -1.706598                 -1.845208   \n",
       "277         0.425279     -1.779581                  0.208143   \n",
       "\n",
       "     AU45_r__sum_values  AU45_r__variance  AU45_r__standard_deviation  \\\n",
       "0              0.520966          1.700927                    1.712210   \n",
       "1             -0.504468          0.296375                    0.440450   \n",
       "2              0.129283         -0.279627                   -0.201661   \n",
       "3             -0.587993          0.094357                    0.226315   \n",
       "4             -1.239117         -0.246984                   -0.162414   \n",
       "..                  ...               ...                         ...   \n",
       "273           -0.142084          0.642278                    0.784992   \n",
       "274           -0.586609         -0.362405                   -0.303044   \n",
       "275           -2.381393          4.280036                    3.507346   \n",
       "276           -0.958863         -0.594948                   -0.603916   \n",
       "277            0.696288          6.381711                    4.701091   \n",
       "\n",
       "     AU45_r__maximum  AU45_r__mean  AU45_r__root_mean_square  \n",
       "0           0.830151      1.741972                  1.745418  \n",
       "1           0.760722      1.243173                  0.665506  \n",
       "2           0.014352     -0.478731                 -0.279724  \n",
       "3          -0.645230      0.514820                  0.302852  \n",
       "4           0.639220     -1.034420                 -0.377156  \n",
       "..               ...           ...                       ...  \n",
       "273         0.864866      0.560518                  0.737070  \n",
       "274         0.326786     -0.488608                 -0.360082  \n",
       "275         0.517718      2.061400                  3.218211  \n",
       "276        -0.315439     -0.770324                 -0.661360  \n",
       "277         4.440496      2.616941                  4.291136  \n",
       "\n",
       "[278 rows x 124 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df = pd.read_csv('/Users/dionnespaltman/Desktop/V6/merged_df_11-06-2024.csv', sep=',')\n",
    "merged_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Stage', 'Gender', 'Date', 'Location', 'Condition', 'Faintness', 'Dizziness', 'Weakness', 'Lightheadedness', 'Fear', 'Tension', 'Stress', 'Physical_sum', 'Psychological_sum', 'Sum_VVR', 'Sum_12', 'Sum_456', 'Sum_4567', 'Sum_1', 'Sum_2', 'VVR_group', 'AU01_r__sum_values', 'AU01_r__variance', 'AU01_r__standard_deviation', 'AU01_r__maximum', 'AU01_r__mean', 'AU01_r__root_mean_square', 'AU02_r__sum_values', 'AU02_r__variance', 'AU02_r__standard_deviation', 'AU02_r__maximum', 'AU02_r__mean', 'AU02_r__root_mean_square', 'AU04_r__sum_values', 'AU04_r__variance', 'AU04_r__standard_deviation', 'AU04_r__maximum', 'AU04_r__mean', 'AU04_r__root_mean_square', 'AU05_r__sum_values', 'AU05_r__variance', 'AU05_r__standard_deviation', 'AU05_r__maximum', 'AU05_r__mean', 'AU05_r__root_mean_square', 'AU06_r__sum_values', 'AU06_r__variance', 'AU06_r__standard_deviation', 'AU06_r__maximum', 'AU06_r__mean', 'AU06_r__root_mean_square', 'AU07_r__sum_values', 'AU07_r__variance', 'AU07_r__standard_deviation', 'AU07_r__maximum', 'AU07_r__mean', 'AU07_r__root_mean_square', 'AU09_r__sum_values', 'AU09_r__variance', 'AU09_r__standard_deviation', 'AU09_r__maximum', 'AU09_r__mean', 'AU09_r__root_mean_square', 'AU10_r__sum_values', 'AU10_r__variance', 'AU10_r__standard_deviation', 'AU10_r__maximum', 'AU10_r__mean', 'AU10_r__root_mean_square', 'AU12_r__sum_values', 'AU12_r__variance', 'AU12_r__standard_deviation', 'AU12_r__maximum', 'AU12_r__mean', 'AU12_r__root_mean_square', 'AU14_r__sum_values', 'AU14_r__variance', 'AU14_r__standard_deviation', 'AU14_r__maximum', 'AU14_r__mean', 'AU14_r__root_mean_square', 'AU15_r__sum_values', 'AU15_r__variance', 'AU15_r__standard_deviation', 'AU15_r__maximum', 'AU15_r__mean', 'AU15_r__root_mean_square', 'AU17_r__sum_values', 'AU17_r__variance', 'AU17_r__standard_deviation', 'AU17_r__maximum', 'AU17_r__mean', 'AU17_r__root_mean_square', 'AU20_r__sum_values', 'AU20_r__variance', 'AU20_r__standard_deviation', 'AU20_r__maximum', 'AU20_r__mean', 'AU20_r__root_mean_square', 'AU23_r__sum_values', 'AU23_r__variance', 'AU23_r__standard_deviation', 'AU23_r__maximum', 'AU23_r__mean', 'AU23_r__root_mean_square', 'AU25_r__sum_values', 'AU25_r__variance', 'AU25_r__standard_deviation', 'AU25_r__maximum', 'AU25_r__mean', 'AU25_r__root_mean_square', 'AU26_r__sum_values', 'AU26_r__variance', 'AU26_r__standard_deviation', 'AU26_r__maximum', 'AU26_r__mean', 'AU26_r__root_mean_square', 'AU45_r__sum_values', 'AU45_r__variance', 'AU45_r__standard_deviation', 'AU45_r__maximum', 'AU45_r__mean', 'AU45_r__root_mean_square']\n"
     ]
    }
   ],
   "source": [
    "print(list(merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 124)\n"
     ]
    }
   ],
   "source": [
    "# Make this copy to save the information easily without having to import it again \n",
    "copy_merged_df = merged_df\n",
    "print(copy_merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_drop = ['Stage', 'Gender', 'Date', 'Location', 'Condition', 'Faintness',\n",
    "#                     'Dizziness', 'Weakness', 'Lightheadedness', 'Fear', 'Tension', 'Stress', 'Physical_sum', \n",
    "#                     'Psychological_sum', 'Sum_VVR', 'Sum_12', 'Sum_456', 'Sum_4567']\n",
    "\n",
    "columns_to_drop = ['Stage', 'Location', 'Faintness',\n",
    "                    'Dizziness', 'Weakness', 'Lightheadedness', 'Fear', 'Tension', 'Stress', 'Physical_sum', \n",
    "                    'Psychological_sum', 'Sum_VVR', 'Sum_12']\n",
    "\n",
    "merged_df = merged_df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Gender', 'Date', 'Condition', 'Sum_456', 'Sum_4567', 'Sum_1', 'Sum_2', 'VVR_group', 'AU01_r__sum_values', 'AU01_r__variance', 'AU01_r__standard_deviation', 'AU01_r__maximum', 'AU01_r__mean', 'AU01_r__root_mean_square', 'AU02_r__sum_values', 'AU02_r__variance', 'AU02_r__standard_deviation', 'AU02_r__maximum', 'AU02_r__mean', 'AU02_r__root_mean_square', 'AU04_r__sum_values', 'AU04_r__variance', 'AU04_r__standard_deviation', 'AU04_r__maximum', 'AU04_r__mean', 'AU04_r__root_mean_square', 'AU05_r__sum_values', 'AU05_r__variance', 'AU05_r__standard_deviation', 'AU05_r__maximum', 'AU05_r__mean', 'AU05_r__root_mean_square', 'AU06_r__sum_values', 'AU06_r__variance', 'AU06_r__standard_deviation', 'AU06_r__maximum', 'AU06_r__mean', 'AU06_r__root_mean_square', 'AU07_r__sum_values', 'AU07_r__variance', 'AU07_r__standard_deviation', 'AU07_r__maximum', 'AU07_r__mean', 'AU07_r__root_mean_square', 'AU09_r__sum_values', 'AU09_r__variance', 'AU09_r__standard_deviation', 'AU09_r__maximum', 'AU09_r__mean', 'AU09_r__root_mean_square', 'AU10_r__sum_values', 'AU10_r__variance', 'AU10_r__standard_deviation', 'AU10_r__maximum', 'AU10_r__mean', 'AU10_r__root_mean_square', 'AU12_r__sum_values', 'AU12_r__variance', 'AU12_r__standard_deviation', 'AU12_r__maximum', 'AU12_r__mean', 'AU12_r__root_mean_square', 'AU14_r__sum_values', 'AU14_r__variance', 'AU14_r__standard_deviation', 'AU14_r__maximum', 'AU14_r__mean', 'AU14_r__root_mean_square', 'AU15_r__sum_values', 'AU15_r__variance', 'AU15_r__standard_deviation', 'AU15_r__maximum', 'AU15_r__mean', 'AU15_r__root_mean_square', 'AU17_r__sum_values', 'AU17_r__variance', 'AU17_r__standard_deviation', 'AU17_r__maximum', 'AU17_r__mean', 'AU17_r__root_mean_square', 'AU20_r__sum_values', 'AU20_r__variance', 'AU20_r__standard_deviation', 'AU20_r__maximum', 'AU20_r__mean', 'AU20_r__root_mean_square', 'AU23_r__sum_values', 'AU23_r__variance', 'AU23_r__standard_deviation', 'AU23_r__maximum', 'AU23_r__mean', 'AU23_r__root_mean_square', 'AU25_r__sum_values', 'AU25_r__variance', 'AU25_r__standard_deviation', 'AU25_r__maximum', 'AU25_r__mean', 'AU25_r__root_mean_square', 'AU26_r__sum_values', 'AU26_r__variance', 'AU26_r__standard_deviation', 'AU26_r__maximum', 'AU26_r__mean', 'AU26_r__root_mean_square', 'AU45_r__sum_values', 'AU45_r__variance', 'AU45_r__standard_deviation', 'AU45_r__maximum', 'AU45_r__mean', 'AU45_r__root_mean_square']\n"
     ]
    }
   ],
   "source": [
    "print(list(merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 111)\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the columns I use to predict, so all my features. I need these as a list to establish my featurizer. \n",
    "I have 102 features from TS fresh and then I added the two VVR measurements from stage 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n"
     ]
    }
   ],
   "source": [
    "columns_ts_fresh = ['AU01_r__sum_values', 'AU01_r__variance', 'AU01_r__standard_deviation', 'AU01_r__maximum', \n",
    "                    'AU01_r__mean', 'AU01_r__root_mean_square', 'AU02_r__sum_values', 'AU02_r__variance', \n",
    "                    'AU02_r__standard_deviation', 'AU02_r__maximum', 'AU02_r__mean', 'AU02_r__root_mean_square', \n",
    "                    'AU04_r__sum_values', 'AU04_r__variance', 'AU04_r__standard_deviation', 'AU04_r__maximum', \n",
    "                    'AU04_r__mean', 'AU04_r__root_mean_square', 'AU05_r__sum_values', 'AU05_r__variance',\n",
    "                    'AU05_r__standard_deviation', 'AU05_r__maximum', 'AU05_r__mean', 'AU05_r__root_mean_square', \n",
    "                    'AU06_r__sum_values', 'AU06_r__variance', 'AU06_r__standard_deviation', 'AU06_r__maximum', \n",
    "                    'AU06_r__mean', 'AU06_r__root_mean_square', 'AU07_r__sum_values', 'AU07_r__variance', \n",
    "                    'AU07_r__standard_deviation', 'AU07_r__maximum', 'AU07_r__mean', 'AU07_r__root_mean_square', \n",
    "                    'AU09_r__sum_values', 'AU09_r__variance', 'AU09_r__standard_deviation', 'AU09_r__maximum',\n",
    "                    'AU09_r__mean', 'AU09_r__root_mean_square', 'AU10_r__sum_values', 'AU10_r__variance', \n",
    "                    'AU10_r__standard_deviation', 'AU10_r__maximum', 'AU10_r__mean', 'AU10_r__root_mean_square',\n",
    "                    'AU12_r__sum_values', 'AU12_r__variance', 'AU12_r__standard_deviation', 'AU12_r__maximum', \n",
    "                    'AU12_r__mean', 'AU12_r__root_mean_square', 'AU14_r__sum_values', 'AU14_r__variance', \n",
    "                    'AU14_r__standard_deviation', 'AU14_r__maximum', 'AU14_r__mean', 'AU14_r__root_mean_square', \n",
    "                    'AU15_r__sum_values', 'AU15_r__variance', 'AU15_r__standard_deviation', 'AU15_r__maximum', \n",
    "                    'AU15_r__mean', 'AU15_r__root_mean_square', 'AU17_r__sum_values', 'AU17_r__variance', \n",
    "                    'AU17_r__standard_deviation', 'AU17_r__maximum', 'AU17_r__mean', 'AU17_r__root_mean_square', \n",
    "                    'AU20_r__sum_values', 'AU20_r__variance', 'AU20_r__standard_deviation', 'AU20_r__maximum', \n",
    "                    'AU20_r__mean', 'AU20_r__root_mean_square', 'AU23_r__sum_values', 'AU23_r__variance', \n",
    "                    'AU23_r__standard_deviation', 'AU23_r__maximum', 'AU23_r__mean', 'AU23_r__root_mean_square', \n",
    "                    'AU25_r__sum_values', 'AU25_r__variance', 'AU25_r__standard_deviation', 'AU25_r__maximum', \n",
    "                    'AU25_r__mean', 'AU25_r__root_mean_square', 'AU26_r__sum_values', 'AU26_r__variance', \n",
    "                    'AU26_r__standard_deviation', 'AU26_r__maximum', 'AU26_r__mean', 'AU26_r__root_mean_square', \n",
    "                    'AU45_r__sum_values', 'AU45_r__variance', 'AU45_r__standard_deviation', 'AU45_r__maximum', \n",
    "                    'AU45_r__mean', 'AU45_r__root_mean_square']\n",
    "\n",
    "print(len(columns_ts_fresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test split\n",
    "May  30, 2024: \n",
    "- In total, we have 104 participants.\n",
    "- I started with a test size of 20%. Then there are 83 people in the train set and 21 in the test set. With a test size of 30#, there are 72 people in the train set and 32 in the test set. \n",
    "- Naturally, we stratify on VVR_group. \n",
    "\n",
    "June 4, 2024: \n",
    "- In total, we have 111 participants.\n",
    "- I started with a test size of 20%. Then there are 88 people in the train set and 23 in the test set. With a test size of 30% there are 77 people in the train set and 34 in the test set. \n",
    "- Naturally, we stratify on VVR_group. \n",
    "\n",
    "June 11, 2024: \n",
    "- In total, we have 278 participants. \n",
    "- Test size of 20%: 222 in the train and 56 in the test set. \n",
    "- Test size of 30%: 184 in the train and 84 in the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "May 30, 2024: Unfortunately, the test set is very small with only 7 people in the high VVR condition. \n",
    "\n",
    "June 3, 2024: The test set is very small with only 11 people in the high VVR condition. \n",
    "\n",
    "June 11, 2024: 56 people is the low VVR group and 28 in the high VVR group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying SMOTE\n",
    "We apply SMOTE on the train data. The strategy is to make the minority as big as the majority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278, 107)\n",
      "(278,)\n",
      "(194, 107)\n",
      "(194,)\n",
      "(84, 107)\n",
      "(84,)\n",
      "(258, 107)\n",
      "(258,)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split data into features and target\n",
    "X = merged_df.drop(columns=['ID', 'Gender', 'VVR_group', 'Date']) \n",
    "y = merged_df['VVR_group'] \n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training set\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42, k_neighbors=5)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train_smote.shape)\n",
    "print(y_train_smote.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(84, 108)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Split data into features and target\n",
    "X_gender = merged_df.drop(columns=['ID', 'VVR_group', 'Date']) \n",
    "y_gender = merged_df['VVR_group'] \n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train_gender, X_test_gender, y_train_gender, y_test_gender = train_test_split(X_gender, y_gender, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_test_gender.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_gender.to_csv('/Users/dionnespaltman/Desktop/V6/X_test_gender_15-06-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('/Users/dionnespaltman/Desktop/V6/X_test_13-06-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 129, 1: 65})\n",
      "Resampled dataset shape Counter({1: 129, 0: 129})\n"
     ]
    }
   ],
   "source": [
    "# Print original class distribution\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "# Print resampled class distribution\n",
    "print('Resampled dataset shape %s' % Counter(y_train_smote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Condition', 'Sum_456', 'Sum_1', 'Sum_2', 'AU01_r__sum_values', 'AU01_r__variance', 'AU01_r__standard_deviation', 'AU01_r__maximum', 'AU01_r__mean', 'AU01_r__root_mean_square', 'AU02_r__sum_values', 'AU02_r__variance', 'AU02_r__standard_deviation', 'AU02_r__maximum', 'AU02_r__mean', 'AU02_r__root_mean_square', 'AU04_r__sum_values', 'AU04_r__variance', 'AU04_r__standard_deviation', 'AU04_r__maximum', 'AU04_r__mean', 'AU04_r__root_mean_square', 'AU05_r__sum_values', 'AU05_r__variance', 'AU05_r__standard_deviation', 'AU05_r__maximum', 'AU05_r__mean', 'AU05_r__root_mean_square', 'AU06_r__sum_values', 'AU06_r__variance', 'AU06_r__standard_deviation', 'AU06_r__maximum', 'AU06_r__mean', 'AU06_r__root_mean_square', 'AU07_r__sum_values', 'AU07_r__variance', 'AU07_r__standard_deviation', 'AU07_r__maximum', 'AU07_r__mean', 'AU07_r__root_mean_square', 'AU09_r__sum_values', 'AU09_r__variance', 'AU09_r__standard_deviation', 'AU09_r__maximum', 'AU09_r__mean', 'AU09_r__root_mean_square', 'AU10_r__sum_values', 'AU10_r__variance', 'AU10_r__standard_deviation', 'AU10_r__maximum', 'AU10_r__mean', 'AU10_r__root_mean_square', 'AU12_r__sum_values', 'AU12_r__variance', 'AU12_r__standard_deviation', 'AU12_r__maximum', 'AU12_r__mean', 'AU12_r__root_mean_square', 'AU14_r__sum_values', 'AU14_r__variance', 'AU14_r__standard_deviation', 'AU14_r__maximum', 'AU14_r__mean', 'AU14_r__root_mean_square', 'AU15_r__sum_values', 'AU15_r__variance', 'AU15_r__standard_deviation', 'AU15_r__maximum', 'AU15_r__mean', 'AU15_r__root_mean_square', 'AU17_r__sum_values', 'AU17_r__variance', 'AU17_r__standard_deviation', 'AU17_r__maximum', 'AU17_r__mean', 'AU17_r__root_mean_square', 'AU20_r__sum_values', 'AU20_r__variance', 'AU20_r__standard_deviation', 'AU20_r__maximum', 'AU20_r__mean', 'AU20_r__root_mean_square', 'AU23_r__sum_values', 'AU23_r__variance', 'AU23_r__standard_deviation', 'AU23_r__maximum', 'AU23_r__mean', 'AU23_r__root_mean_square', 'AU25_r__sum_values', 'AU25_r__variance', 'AU25_r__standard_deviation', 'AU25_r__maximum', 'AU25_r__mean', 'AU25_r__root_mean_square', 'AU26_r__sum_values', 'AU26_r__variance', 'AU26_r__standard_deviation', 'AU26_r__maximum', 'AU26_r__mean', 'AU26_r__root_mean_square', 'AU45_r__sum_values', 'AU45_r__variance', 'AU45_r__standard_deviation', 'AU45_r__maximum', 'AU45_r__mean', 'AU45_r__root_mean_square']\n"
     ]
    }
   ],
   "source": [
    "print(list(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote.to_csv('/Users/dionnespaltman/Desktop/V6/X_train_smote_12-06-2024.csv')\n",
    "y_train_smote.to_csv('/Users/dionnespaltman/Desktop/V6/y_train_smote_12-06-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('/Users/dionnespaltman/Desktop/V6/X_test_12-06-2024.csv')\n",
    "y_test.to_csv('/Users/dionnespaltman/Desktop/V6/y_test_12-06-2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding class weights\n",
    "\n",
    "I will add class weights to my models, because of my inbalanced data set. \n",
    "https://medium.com/@ravi.abhinav4/improving-class-imbalance-with-class-weights-in-machine-learning-af072fdd4aa4 \n",
    "\n",
    "May 30, 2024: {0: 0.6428571428571429, 1: 2.25}\n",
    "\n",
    "June 3, 2024: {0: 0.7549019607843137, 1: 1.4807692307692308}\n",
    "\n",
    "June 11, 2024:  {0: 0.7461538461538462, 1: 1.515625}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.751937984496124, 1: 1.4923076923076923}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_class_weights(y):\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "    total_samples = len(y)\n",
    "    class_weights = {}\n",
    "\n",
    "    for class_label, class_count in zip(unique_classes, class_counts):\n",
    "        class_weight = total_samples / (2.0 * class_count)\n",
    "        class_weights[class_label] = class_weight\n",
    "\n",
    "    return class_weights\n",
    "\n",
    "# Assuming 'y' contains the class labels (0s and 1s) for the binary classification problem\n",
    "class_weights = calculate_class_weights(y_train)\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data distibution: old data vs new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_june = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/X_train_resampled.csv')\n",
    "y_train_june = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/y_train_resampled.csv')\n",
    "X_test_june = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/X_test.csv')\n",
    "y_test_june = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_may = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/X_train_res.csv')\n",
    "y_train_may = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/y_train_res.csv')\n",
    "X_test_may = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/X_test.csv')\n",
    "y_test_may = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    56\n",
      "0    56\n",
      "Name: VVR_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts_train_may = y_train_may['VVR_group'].value_counts()\n",
    "print(counts_train_may)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    51\n",
      "0    51\n",
      "Name: VVR_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts_train_june = y_train_june['VVR_group'].value_counts()\n",
    "print(counts_train_june)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    25\n",
      "1     7\n",
      "Name: VVR_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts_test_may = y_test_may['VVR_group'].value_counts()\n",
    "print(counts_test_may)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    23\n",
      "1    11\n",
      "Name: VVR_group, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts_test_june = y_test_june['VVR_group'].value_counts()\n",
    "print(counts_test_june)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
