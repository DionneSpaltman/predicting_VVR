{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import auc, precision_recall_curve, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into pandas dataframes\n",
    "X_train = pd.read_csv('/Users/dionnespaltman/Desktop/V6/X_train_smote_12-06-2024.csv')\n",
    "y_train = pd.read_csv('/Users/dionnespaltman/Desktop/V6/y_train_smote_12-06-2024.csv')\n",
    "X_test = pd.read_csv('/Users/dionnespaltman/Desktop/V6/X_test_12-06-2024.csv')\n",
    "y_test = pd.read_csv('/Users/dionnespaltman/Desktop/V6/y_test_12-06-2024.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnamed columns \n",
    "X_train = X_train.drop(columns='Unnamed: 0', axis=1)\n",
    "y_train = y_train.drop(columns='Unnamed: 0', axis=1)\n",
    "X_test = X_test.drop(columns='Unnamed: 0', axis=1)\n",
    "y_test = y_test.drop(columns='Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Sum_1', 'Sum_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=columns_to_drop, axis=1)\n",
    "X_test = X_test.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "['Condition', 'Sum_456', 'AU01_r__sum_values', 'AU01_r__variance', 'AU01_r__standard_deviation', 'AU01_r__maximum', 'AU01_r__mean', 'AU01_r__root_mean_square', 'AU02_r__sum_values', 'AU02_r__variance', 'AU02_r__standard_deviation', 'AU02_r__maximum', 'AU02_r__mean', 'AU02_r__root_mean_square', 'AU04_r__sum_values', 'AU04_r__variance', 'AU04_r__standard_deviation', 'AU04_r__maximum', 'AU04_r__mean', 'AU04_r__root_mean_square', 'AU05_r__sum_values', 'AU05_r__variance', 'AU05_r__standard_deviation', 'AU05_r__maximum', 'AU05_r__mean', 'AU05_r__root_mean_square', 'AU06_r__sum_values', 'AU06_r__variance', 'AU06_r__standard_deviation', 'AU06_r__maximum', 'AU06_r__mean', 'AU06_r__root_mean_square', 'AU07_r__sum_values', 'AU07_r__variance', 'AU07_r__standard_deviation', 'AU07_r__maximum', 'AU07_r__mean', 'AU07_r__root_mean_square', 'AU09_r__sum_values', 'AU09_r__variance', 'AU09_r__standard_deviation', 'AU09_r__maximum', 'AU09_r__mean', 'AU09_r__root_mean_square', 'AU10_r__sum_values', 'AU10_r__variance', 'AU10_r__standard_deviation', 'AU10_r__maximum', 'AU10_r__mean', 'AU10_r__root_mean_square', 'AU12_r__sum_values', 'AU12_r__variance', 'AU12_r__standard_deviation', 'AU12_r__maximum', 'AU12_r__mean', 'AU12_r__root_mean_square', 'AU14_r__sum_values', 'AU14_r__variance', 'AU14_r__standard_deviation', 'AU14_r__maximum', 'AU14_r__mean', 'AU14_r__root_mean_square', 'AU15_r__sum_values', 'AU15_r__variance', 'AU15_r__standard_deviation', 'AU15_r__maximum', 'AU15_r__mean', 'AU15_r__root_mean_square', 'AU17_r__sum_values', 'AU17_r__variance', 'AU17_r__standard_deviation', 'AU17_r__maximum', 'AU17_r__mean', 'AU17_r__root_mean_square', 'AU20_r__sum_values', 'AU20_r__variance', 'AU20_r__standard_deviation', 'AU20_r__maximum', 'AU20_r__mean', 'AU20_r__root_mean_square', 'AU23_r__sum_values', 'AU23_r__variance', 'AU23_r__standard_deviation', 'AU23_r__maximum', 'AU23_r__mean', 'AU23_r__root_mean_square', 'AU25_r__sum_values', 'AU25_r__variance', 'AU25_r__standard_deviation', 'AU25_r__maximum', 'AU25_r__mean', 'AU25_r__root_mean_square', 'AU26_r__sum_values', 'AU26_r__variance', 'AU26_r__standard_deviation', 'AU26_r__maximum', 'AU26_r__mean', 'AU26_r__root_mean_square', 'AU45_r__sum_values', 'AU45_r__variance', 'AU45_r__standard_deviation', 'AU45_r__maximum', 'AU45_r__mean', 'AU45_r__root_mean_square']\n",
      "\n",
      "104\n",
      "['Condition', 'Sum_456', 'AU01_r__sum_values', 'AU01_r__variance', 'AU01_r__standard_deviation', 'AU01_r__maximum', 'AU01_r__mean', 'AU01_r__root_mean_square', 'AU02_r__sum_values', 'AU02_r__variance', 'AU02_r__standard_deviation', 'AU02_r__maximum', 'AU02_r__mean', 'AU02_r__root_mean_square', 'AU04_r__sum_values', 'AU04_r__variance', 'AU04_r__standard_deviation', 'AU04_r__maximum', 'AU04_r__mean', 'AU04_r__root_mean_square', 'AU05_r__sum_values', 'AU05_r__variance', 'AU05_r__standard_deviation', 'AU05_r__maximum', 'AU05_r__mean', 'AU05_r__root_mean_square', 'AU06_r__sum_values', 'AU06_r__variance', 'AU06_r__standard_deviation', 'AU06_r__maximum', 'AU06_r__mean', 'AU06_r__root_mean_square', 'AU07_r__sum_values', 'AU07_r__variance', 'AU07_r__standard_deviation', 'AU07_r__maximum', 'AU07_r__mean', 'AU07_r__root_mean_square', 'AU09_r__sum_values', 'AU09_r__variance', 'AU09_r__standard_deviation', 'AU09_r__maximum', 'AU09_r__mean', 'AU09_r__root_mean_square', 'AU10_r__sum_values', 'AU10_r__variance', 'AU10_r__standard_deviation', 'AU10_r__maximum', 'AU10_r__mean', 'AU10_r__root_mean_square', 'AU12_r__sum_values', 'AU12_r__variance', 'AU12_r__standard_deviation', 'AU12_r__maximum', 'AU12_r__mean', 'AU12_r__root_mean_square', 'AU14_r__sum_values', 'AU14_r__variance', 'AU14_r__standard_deviation', 'AU14_r__maximum', 'AU14_r__mean', 'AU14_r__root_mean_square', 'AU15_r__sum_values', 'AU15_r__variance', 'AU15_r__standard_deviation', 'AU15_r__maximum', 'AU15_r__mean', 'AU15_r__root_mean_square', 'AU17_r__sum_values', 'AU17_r__variance', 'AU17_r__standard_deviation', 'AU17_r__maximum', 'AU17_r__mean', 'AU17_r__root_mean_square', 'AU20_r__sum_values', 'AU20_r__variance', 'AU20_r__standard_deviation', 'AU20_r__maximum', 'AU20_r__mean', 'AU20_r__root_mean_square', 'AU23_r__sum_values', 'AU23_r__variance', 'AU23_r__standard_deviation', 'AU23_r__maximum', 'AU23_r__mean', 'AU23_r__root_mean_square', 'AU25_r__sum_values', 'AU25_r__variance', 'AU25_r__standard_deviation', 'AU25_r__maximum', 'AU25_r__mean', 'AU25_r__root_mean_square', 'AU26_r__sum_values', 'AU26_r__variance', 'AU26_r__standard_deviation', 'AU26_r__maximum', 'AU26_r__mean', 'AU26_r__root_mean_square', 'AU45_r__sum_values', 'AU45_r__variance', 'AU45_r__standard_deviation', 'AU45_r__maximum', 'AU45_r__mean', 'AU45_r__root_mean_square']\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train.columns))\n",
    "print(list(X_train.columns))\n",
    "print()\n",
    "print(len(X_test.columns))\n",
    "print(list(X_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a 1-dimensional NumPy array\n",
    "y_train= y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>Sum_456</th>\n",
       "      <th>AU01_r__sum_values</th>\n",
       "      <th>AU01_r__variance</th>\n",
       "      <th>AU01_r__standard_deviation</th>\n",
       "      <th>AU01_r__maximum</th>\n",
       "      <th>AU01_r__mean</th>\n",
       "      <th>AU01_r__root_mean_square</th>\n",
       "      <th>AU02_r__sum_values</th>\n",
       "      <th>AU02_r__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_r__standard_deviation</th>\n",
       "      <th>AU26_r__maximum</th>\n",
       "      <th>AU26_r__mean</th>\n",
       "      <th>AU26_r__root_mean_square</th>\n",
       "      <th>AU45_r__sum_values</th>\n",
       "      <th>AU45_r__variance</th>\n",
       "      <th>AU45_r__standard_deviation</th>\n",
       "      <th>AU45_r__maximum</th>\n",
       "      <th>AU45_r__mean</th>\n",
       "      <th>AU45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.919310</td>\n",
       "      <td>0.742910</td>\n",
       "      <td>0.847697</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>0.830565</td>\n",
       "      <td>0.850749</td>\n",
       "      <td>0.485652</td>\n",
       "      <td>-0.019882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.408243</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>-0.263230</td>\n",
       "      <td>-0.352093</td>\n",
       "      <td>0.970489</td>\n",
       "      <td>0.303553</td>\n",
       "      <td>0.447869</td>\n",
       "      <td>0.118497</td>\n",
       "      <td>1.010999</td>\n",
       "      <td>0.604244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>-0.631136</td>\n",
       "      <td>-0.940957</td>\n",
       "      <td>-1.033638</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>-1.333231</td>\n",
       "      <td>-1.131787</td>\n",
       "      <td>-0.198166</td>\n",
       "      <td>-0.410164</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.807795</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>-1.083828</td>\n",
       "      <td>-0.956263</td>\n",
       "      <td>0.265217</td>\n",
       "      <td>-0.581863</td>\n",
       "      <td>-0.586285</td>\n",
       "      <td>-0.436941</td>\n",
       "      <td>-0.690791</td>\n",
       "      <td>-0.627719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.815800</td>\n",
       "      <td>0.489371</td>\n",
       "      <td>0.618471</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>0.502919</td>\n",
       "      <td>0.589230</td>\n",
       "      <td>1.220328</td>\n",
       "      <td>-0.116460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106153</td>\n",
       "      <td>0.338793</td>\n",
       "      <td>-0.903012</td>\n",
       "      <td>-0.467784</td>\n",
       "      <td>2.738438</td>\n",
       "      <td>0.349732</td>\n",
       "      <td>0.495312</td>\n",
       "      <td>0.760722</td>\n",
       "      <td>1.340506</td>\n",
       "      <td>0.733533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>-1.082503</td>\n",
       "      <td>-0.947092</td>\n",
       "      <td>-1.043026</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>-0.992134</td>\n",
       "      <td>-1.048249</td>\n",
       "      <td>-0.932584</td>\n",
       "      <td>-0.623317</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.011057</td>\n",
       "      <td>-1.321739</td>\n",
       "      <td>-0.995226</td>\n",
       "      <td>-1.029314</td>\n",
       "      <td>-0.648617</td>\n",
       "      <td>-0.463357</td>\n",
       "      <td>-0.430560</td>\n",
       "      <td>-1.235383</td>\n",
       "      <td>-0.347166</td>\n",
       "      <td>-0.420355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>-0.468956</td>\n",
       "      <td>0.765159</td>\n",
       "      <td>0.867251</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>0.251033</td>\n",
       "      <td>0.703075</td>\n",
       "      <td>-0.188708</td>\n",
       "      <td>0.531833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.891051</td>\n",
       "      <td>-0.716337</td>\n",
       "      <td>-0.741624</td>\n",
       "      <td>-0.842706</td>\n",
       "      <td>-0.648377</td>\n",
       "      <td>0.115383</td>\n",
       "      <td>0.249103</td>\n",
       "      <td>0.864866</td>\n",
       "      <td>0.103879</td>\n",
       "      <td>0.211850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>3</td>\n",
       "      <td>34.591267</td>\n",
       "      <td>0.404780</td>\n",
       "      <td>-0.213730</td>\n",
       "      <td>-0.122362</td>\n",
       "      <td>0.044925</td>\n",
       "      <td>0.080427</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>0.151535</td>\n",
       "      <td>-0.241475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300615</td>\n",
       "      <td>0.399711</td>\n",
       "      <td>0.416752</td>\n",
       "      <td>0.357324</td>\n",
       "      <td>0.224620</td>\n",
       "      <td>-0.040184</td>\n",
       "      <td>0.057747</td>\n",
       "      <td>0.705928</td>\n",
       "      <td>-0.190008</td>\n",
       "      <td>-0.008415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>2</td>\n",
       "      <td>35.683517</td>\n",
       "      <td>-0.387304</td>\n",
       "      <td>0.048483</td>\n",
       "      <td>0.186925</td>\n",
       "      <td>0.249664</td>\n",
       "      <td>-0.208703</td>\n",
       "      <td>0.074278</td>\n",
       "      <td>-0.191856</td>\n",
       "      <td>0.240390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653529</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.613156</td>\n",
       "      <td>0.641681</td>\n",
       "      <td>-0.360287</td>\n",
       "      <td>-0.234234</td>\n",
       "      <td>-0.149341</td>\n",
       "      <td>-0.536546</td>\n",
       "      <td>-0.141645</td>\n",
       "      <td>-0.154002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>3</td>\n",
       "      <td>37.630396</td>\n",
       "      <td>0.278411</td>\n",
       "      <td>-0.036299</td>\n",
       "      <td>0.071646</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>0.346129</td>\n",
       "      <td>0.150659</td>\n",
       "      <td>-0.257221</td>\n",
       "      <td>-0.271857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857897</td>\n",
       "      <td>0.385795</td>\n",
       "      <td>1.021472</td>\n",
       "      <td>0.949439</td>\n",
       "      <td>-0.080333</td>\n",
       "      <td>-0.052434</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>0.638470</td>\n",
       "      <td>-0.105022</td>\n",
       "      <td>-0.017082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2</td>\n",
       "      <td>60.436881</td>\n",
       "      <td>1.109901</td>\n",
       "      <td>0.315526</td>\n",
       "      <td>0.453389</td>\n",
       "      <td>-0.718435</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.330545</td>\n",
       "      <td>0.530761</td>\n",
       "      <td>-0.447359</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.563444</td>\n",
       "      <td>-0.007322</td>\n",
       "      <td>-1.529979</td>\n",
       "      <td>-1.582537</td>\n",
       "      <td>2.185380</td>\n",
       "      <td>0.938926</td>\n",
       "      <td>1.060632</td>\n",
       "      <td>0.864866</td>\n",
       "      <td>0.940212</td>\n",
       "      <td>1.043909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2</td>\n",
       "      <td>34.166980</td>\n",
       "      <td>-0.599604</td>\n",
       "      <td>-0.373865</td>\n",
       "      <td>-0.307540</td>\n",
       "      <td>-0.498396</td>\n",
       "      <td>-0.523269</td>\n",
       "      <td>-0.377296</td>\n",
       "      <td>0.036302</td>\n",
       "      <td>-0.066556</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000444</td>\n",
       "      <td>-0.997798</td>\n",
       "      <td>-1.066933</td>\n",
       "      <td>-1.056802</td>\n",
       "      <td>0.263066</td>\n",
       "      <td>0.295149</td>\n",
       "      <td>0.435672</td>\n",
       "      <td>-0.665486</td>\n",
       "      <td>0.597224</td>\n",
       "      <td>0.481804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>258 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Condition    Sum_456  AU01_r__sum_values  AU01_r__variance  \\\n",
       "0            1  36.000000            0.919310          0.742910   \n",
       "1            2  29.000000           -0.631136         -0.940957   \n",
       "2            3  24.000000            1.815800          0.489371   \n",
       "3            1  24.000000           -1.082503         -0.947092   \n",
       "4            3  24.000000           -0.468956          0.765159   \n",
       "..         ...        ...                 ...               ...   \n",
       "253          3  34.591267            0.404780         -0.213730   \n",
       "254          2  35.683517           -0.387304          0.048483   \n",
       "255          3  37.630396            0.278411         -0.036299   \n",
       "256          2  60.436881            1.109901          0.315526   \n",
       "257          2  34.166980           -0.599604         -0.373865   \n",
       "\n",
       "     AU01_r__standard_deviation  AU01_r__maximum  AU01_r__mean  \\\n",
       "0                      0.847697         0.293698      0.830565   \n",
       "1                     -1.033638         0.293698     -1.333231   \n",
       "2                      0.618471         0.293698      0.502919   \n",
       "3                     -1.043026         0.293698     -0.992134   \n",
       "4                      0.867251         0.293698      0.251033   \n",
       "..                          ...              ...           ...   \n",
       "253                   -0.122362         0.044925      0.080427   \n",
       "254                    0.186925         0.249664     -0.208703   \n",
       "255                    0.071646         0.293698      0.346129   \n",
       "256                    0.453389        -0.718435      0.009169   \n",
       "257                   -0.307540        -0.498396     -0.523269   \n",
       "\n",
       "     AU01_r__root_mean_square  AU02_r__sum_values  AU02_r__variance  ...  \\\n",
       "0                    0.850749            0.485652         -0.019882  ...   \n",
       "1                   -1.131787           -0.198166         -0.410164  ...   \n",
       "2                    0.589230            1.220328         -0.116460  ...   \n",
       "3                   -1.048249           -0.932584         -0.623317  ...   \n",
       "4                    0.703075           -0.188708          0.531833  ...   \n",
       "..                        ...                 ...               ...  ...   \n",
       "253                 -0.068330            0.151535         -0.241475  ...   \n",
       "254                  0.074278           -0.191856          0.240390  ...   \n",
       "255                  0.150659           -0.257221         -0.271857  ...   \n",
       "256                  0.330545            0.530761         -0.447359  ...   \n",
       "257                 -0.377296            0.036302         -0.066556  ...   \n",
       "\n",
       "     AU26_r__standard_deviation  AU26_r__maximum  AU26_r__mean  \\\n",
       "0                     -0.408243         0.425279     -0.263230   \n",
       "1                     -0.807795         0.425279     -1.083828   \n",
       "2                     -0.106153         0.338793     -0.903012   \n",
       "3                     -1.011057        -1.321739     -0.995226   \n",
       "4                     -0.891051        -0.716337     -0.741624   \n",
       "..                          ...              ...           ...   \n",
       "253                    0.300615         0.399711      0.416752   \n",
       "254                    0.653529         0.425279      0.613156   \n",
       "255                    0.857897         0.385795      1.021472   \n",
       "256                   -1.563444        -0.007322     -1.529979   \n",
       "257                   -1.000444        -0.997798     -1.066933   \n",
       "\n",
       "     AU26_r__root_mean_square  AU45_r__sum_values  AU45_r__variance  \\\n",
       "0                   -0.352093            0.970489          0.303553   \n",
       "1                   -0.956263            0.265217         -0.581863   \n",
       "2                   -0.467784            2.738438          0.349732   \n",
       "3                   -1.029314           -0.648617         -0.463357   \n",
       "4                   -0.842706           -0.648377          0.115383   \n",
       "..                        ...                 ...               ...   \n",
       "253                  0.357324            0.224620         -0.040184   \n",
       "254                  0.641681           -0.360287         -0.234234   \n",
       "255                  0.949439           -0.080333         -0.052434   \n",
       "256                 -1.582537            2.185380          0.938926   \n",
       "257                 -1.056802            0.263066          0.295149   \n",
       "\n",
       "     AU45_r__standard_deviation  AU45_r__maximum  AU45_r__mean  \\\n",
       "0                      0.447869         0.118497      1.010999   \n",
       "1                     -0.586285        -0.436941     -0.690791   \n",
       "2                      0.495312         0.760722      1.340506   \n",
       "3                     -0.430560        -1.235383     -0.347166   \n",
       "4                      0.249103         0.864866      0.103879   \n",
       "..                          ...              ...           ...   \n",
       "253                    0.057747         0.705928     -0.190008   \n",
       "254                   -0.149341        -0.536546     -0.141645   \n",
       "255                    0.018721         0.638470     -0.105022   \n",
       "256                    1.060632         0.864866      0.940212   \n",
       "257                    0.435672        -0.665486      0.597224   \n",
       "\n",
       "     AU45_r__root_mean_square  \n",
       "0                    0.604244  \n",
       "1                   -0.627719  \n",
       "2                    0.733533  \n",
       "3                   -0.420355  \n",
       "4                    0.211850  \n",
       "..                        ...  \n",
       "253                 -0.008415  \n",
       "254                 -0.154002  \n",
       "255                 -0.017082  \n",
       "256                  1.043909  \n",
       "257                  0.481804  \n",
       "\n",
       "[258 rows x 104 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>Sum_456</th>\n",
       "      <th>AU01_r__sum_values</th>\n",
       "      <th>AU01_r__variance</th>\n",
       "      <th>AU01_r__standard_deviation</th>\n",
       "      <th>AU01_r__maximum</th>\n",
       "      <th>AU01_r__mean</th>\n",
       "      <th>AU01_r__root_mean_square</th>\n",
       "      <th>AU02_r__sum_values</th>\n",
       "      <th>AU02_r__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_r__standard_deviation</th>\n",
       "      <th>AU26_r__maximum</th>\n",
       "      <th>AU26_r__mean</th>\n",
       "      <th>AU26_r__root_mean_square</th>\n",
       "      <th>AU45_r__sum_values</th>\n",
       "      <th>AU45_r__variance</th>\n",
       "      <th>AU45_r__standard_deviation</th>\n",
       "      <th>AU45_r__maximum</th>\n",
       "      <th>AU45_r__mean</th>\n",
       "      <th>AU45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.394144</td>\n",
       "      <td>0.113788</td>\n",
       "      <td>0.253906</td>\n",
       "      <td>-0.241433</td>\n",
       "      <td>0.337966</td>\n",
       "      <td>0.277798</td>\n",
       "      <td>-0.874243</td>\n",
       "      <td>-0.569907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.435610</td>\n",
       "      <td>0.096632</td>\n",
       "      <td>0.288670</td>\n",
       "      <td>0.368635</td>\n",
       "      <td>-0.626277</td>\n",
       "      <td>-0.010494</td>\n",
       "      <td>0.110803</td>\n",
       "      <td>-0.141865</td>\n",
       "      <td>0.104892</td>\n",
       "      <td>0.106922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.825099</td>\n",
       "      <td>-0.190659</td>\n",
       "      <td>-0.069153</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>-0.123168</td>\n",
       "      <td>-0.090616</td>\n",
       "      <td>0.406467</td>\n",
       "      <td>-0.315763</td>\n",
       "      <td>...</td>\n",
       "      <td>1.666168</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>1.754932</td>\n",
       "      <td>1.737696</td>\n",
       "      <td>0.524330</td>\n",
       "      <td>-0.520376</td>\n",
       "      <td>-0.504625</td>\n",
       "      <td>0.864866</td>\n",
       "      <td>-0.575572</td>\n",
       "      <td>-0.536034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.286661</td>\n",
       "      <td>0.569833</td>\n",
       "      <td>0.692545</td>\n",
       "      <td>-0.091596</td>\n",
       "      <td>0.683319</td>\n",
       "      <td>0.695538</td>\n",
       "      <td>-0.134549</td>\n",
       "      <td>0.036436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001568</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.076727</td>\n",
       "      <td>0.030450</td>\n",
       "      <td>-0.968274</td>\n",
       "      <td>-0.966036</td>\n",
       "      <td>-1.148606</td>\n",
       "      <td>-2.450403</td>\n",
       "      <td>-1.112739</td>\n",
       "      <td>-1.163339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.340946</td>\n",
       "      <td>0.853918</td>\n",
       "      <td>0.944420</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>1.052200</td>\n",
       "      <td>0.986488</td>\n",
       "      <td>1.731736</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000224</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>1.243322</td>\n",
       "      <td>1.681337</td>\n",
       "      <td>1.646689</td>\n",
       "      <td>0.774393</td>\n",
       "      <td>0.910237</td>\n",
       "      <td>0.864866</td>\n",
       "      <td>0.405610</td>\n",
       "      <td>0.795791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-1.091775</td>\n",
       "      <td>-1.363165</td>\n",
       "      <td>-1.790147</td>\n",
       "      <td>-1.750502</td>\n",
       "      <td>-1.504745</td>\n",
       "      <td>-1.738265</td>\n",
       "      <td>-0.185078</td>\n",
       "      <td>-0.531768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880432</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.570028</td>\n",
       "      <td>0.745445</td>\n",
       "      <td>0.147565</td>\n",
       "      <td>0.090425</td>\n",
       "      <td>0.222041</td>\n",
       "      <td>0.864866</td>\n",
       "      <td>-0.205765</td>\n",
       "      <td>0.114488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.586570</td>\n",
       "      <td>-0.251573</td>\n",
       "      <td>-0.137412</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>0.077983</td>\n",
       "      <td>-0.080132</td>\n",
       "      <td>0.445783</td>\n",
       "      <td>-0.304901</td>\n",
       "      <td>...</td>\n",
       "      <td>1.589020</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>1.907163</td>\n",
       "      <td>1.772730</td>\n",
       "      <td>0.511612</td>\n",
       "      <td>-0.405438</td>\n",
       "      <td>-0.356858</td>\n",
       "      <td>0.049067</td>\n",
       "      <td>-0.069567</td>\n",
       "      <td>-0.290302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.352037</td>\n",
       "      <td>2.449155</td>\n",
       "      <td>2.157521</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>2.139058</td>\n",
       "      <td>2.180886</td>\n",
       "      <td>1.291554</td>\n",
       "      <td>1.793664</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232566</td>\n",
       "      <td>-0.733634</td>\n",
       "      <td>-0.857109</td>\n",
       "      <td>-1.078772</td>\n",
       "      <td>-0.457404</td>\n",
       "      <td>-0.382910</td>\n",
       "      <td>-0.328588</td>\n",
       "      <td>-0.714660</td>\n",
       "      <td>-0.291292</td>\n",
       "      <td>-0.328794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-0.997972</td>\n",
       "      <td>-0.092138</td>\n",
       "      <td>0.038534</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>-0.262103</td>\n",
       "      <td>-0.050299</td>\n",
       "      <td>-0.832871</td>\n",
       "      <td>-0.036330</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.453697</td>\n",
       "      <td>-1.166064</td>\n",
       "      <td>-1.374354</td>\n",
       "      <td>-1.450532</td>\n",
       "      <td>-0.990030</td>\n",
       "      <td>-0.145579</td>\n",
       "      <td>-0.042962</td>\n",
       "      <td>0.864866</td>\n",
       "      <td>-0.062437</td>\n",
       "      <td>-0.053038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.331540</td>\n",
       "      <td>-0.829194</td>\n",
       "      <td>-0.868273</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>-0.390558</td>\n",
       "      <td>-0.740947</td>\n",
       "      <td>0.849322</td>\n",
       "      <td>0.834394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.839698</td>\n",
       "      <td>-0.543365</td>\n",
       "      <td>-0.677054</td>\n",
       "      <td>-0.783841</td>\n",
       "      <td>-0.145438</td>\n",
       "      <td>-0.223852</td>\n",
       "      <td>-0.134841</td>\n",
       "      <td>-0.315439</td>\n",
       "      <td>-0.185071</td>\n",
       "      <td>-0.154475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.692606</td>\n",
       "      <td>1.893534</td>\n",
       "      <td>1.766233</td>\n",
       "      <td>0.293698</td>\n",
       "      <td>1.343735</td>\n",
       "      <td>1.665517</td>\n",
       "      <td>1.317772</td>\n",
       "      <td>3.063176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229617</td>\n",
       "      <td>0.425279</td>\n",
       "      <td>0.465267</td>\n",
       "      <td>0.343728</td>\n",
       "      <td>-0.936825</td>\n",
       "      <td>-0.962588</td>\n",
       "      <td>-1.143071</td>\n",
       "      <td>-1.443672</td>\n",
       "      <td>-0.980686</td>\n",
       "      <td>-1.123732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Condition  Sum_456  AU01_r__sum_values  AU01_r__variance  \\\n",
       "0           1     26.0           -0.394144          0.113788   \n",
       "1           3     34.0            0.825099         -0.190659   \n",
       "2           3     24.0            0.286661          0.569833   \n",
       "3           2     57.0            2.340946          0.853918   \n",
       "4           3     25.0           -1.091775         -1.363165   \n",
       "..        ...      ...                 ...               ...   \n",
       "79          3     30.0            0.586570         -0.251573   \n",
       "80          3     24.0            1.352037          2.449155   \n",
       "81          1     26.0           -0.997972         -0.092138   \n",
       "82          3     28.0           -0.331540         -0.829194   \n",
       "83          3     34.0            0.692606          1.893534   \n",
       "\n",
       "    AU01_r__standard_deviation  AU01_r__maximum  AU01_r__mean  \\\n",
       "0                     0.253906        -0.241433      0.337966   \n",
       "1                    -0.069153         0.293698     -0.123168   \n",
       "2                     0.692545        -0.091596      0.683319   \n",
       "3                     0.944420         0.293698      1.052200   \n",
       "4                    -1.790147        -1.750502     -1.504745   \n",
       "..                         ...              ...           ...   \n",
       "79                   -0.137412         0.293698      0.077983   \n",
       "80                    2.157521         0.293698      2.139058   \n",
       "81                    0.038534         0.293698     -0.262103   \n",
       "82                   -0.868273         0.293698     -0.390558   \n",
       "83                    1.766233         0.293698      1.343735   \n",
       "\n",
       "    AU01_r__root_mean_square  AU02_r__sum_values  AU02_r__variance  ...  \\\n",
       "0                   0.277798           -0.874243         -0.569907  ...   \n",
       "1                  -0.090616            0.406467         -0.315763  ...   \n",
       "2                   0.695538           -0.134549          0.036436  ...   \n",
       "3                   0.986488            1.731736          0.006584  ...   \n",
       "4                  -1.738265           -0.185078         -0.531768  ...   \n",
       "..                       ...                 ...               ...  ...   \n",
       "79                 -0.080132            0.445783         -0.304901  ...   \n",
       "80                  2.180886            1.291554          1.793664  ...   \n",
       "81                 -0.050299           -0.832871         -0.036330  ...   \n",
       "82                 -0.740947            0.849322          0.834394  ...   \n",
       "83                  1.665517            1.317772          3.063176  ...   \n",
       "\n",
       "    AU26_r__standard_deviation  AU26_r__maximum  AU26_r__mean  \\\n",
       "0                     0.435610         0.096632      0.288670   \n",
       "1                     1.666168         0.425279      1.754932   \n",
       "2                    -0.001568         0.425279      0.076727   \n",
       "3                     2.000224         0.425279      1.243322   \n",
       "4                     0.880432         0.425279      0.570028   \n",
       "..                         ...              ...           ...   \n",
       "79                    1.589020         0.425279      1.907163   \n",
       "80                   -1.232566        -0.733634     -0.857109   \n",
       "81                   -1.453697        -1.166064     -1.374354   \n",
       "82                   -0.839698        -0.543365     -0.677054   \n",
       "83                    0.229617         0.425279      0.465267   \n",
       "\n",
       "    AU26_r__root_mean_square  AU45_r__sum_values  AU45_r__variance  \\\n",
       "0                   0.368635           -0.626277         -0.010494   \n",
       "1                   1.737696            0.524330         -0.520376   \n",
       "2                   0.030450           -0.968274         -0.966036   \n",
       "3                   1.681337            1.646689          0.774393   \n",
       "4                   0.745445            0.147565          0.090425   \n",
       "..                       ...                 ...               ...   \n",
       "79                  1.772730            0.511612         -0.405438   \n",
       "80                 -1.078772           -0.457404         -0.382910   \n",
       "81                 -1.450532           -0.990030         -0.145579   \n",
       "82                 -0.783841           -0.145438         -0.223852   \n",
       "83                  0.343728           -0.936825         -0.962588   \n",
       "\n",
       "    AU45_r__standard_deviation  AU45_r__maximum  AU45_r__mean  \\\n",
       "0                     0.110803        -0.141865      0.104892   \n",
       "1                    -0.504625         0.864866     -0.575572   \n",
       "2                    -1.148606        -2.450403     -1.112739   \n",
       "3                     0.910237         0.864866      0.405610   \n",
       "4                     0.222041         0.864866     -0.205765   \n",
       "..                         ...              ...           ...   \n",
       "79                   -0.356858         0.049067     -0.069567   \n",
       "80                   -0.328588        -0.714660     -0.291292   \n",
       "81                   -0.042962         0.864866     -0.062437   \n",
       "82                   -0.134841        -0.315439     -0.185071   \n",
       "83                   -1.143071        -1.443672     -0.980686   \n",
       "\n",
       "    AU45_r__root_mean_square  \n",
       "0                   0.106922  \n",
       "1                  -0.536034  \n",
       "2                  -1.163339  \n",
       "3                   0.795791  \n",
       "4                   0.114488  \n",
       "..                       ...  \n",
       "79                 -0.290302  \n",
       "80                 -0.328794  \n",
       "81                 -0.053038  \n",
       "82                 -0.154475  \n",
       "83                 -1.123732  \n",
       "\n",
       "[84 rows x 104 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display each dataframe to verify the loading\n",
    "print(\"X_train:\")\n",
    "display(X_train)\n",
    "\n",
    "print(\"\\nX_test:\")\n",
    "display(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline():\n",
    "    \"\"\"Builds the machine learning pipeline with RFE and RandomForestClassifier.\"\"\"\n",
    "    rfe = RFE(estimator=DecisionTreeClassifier(random_state=0))  # Recursive feature elimination with a decision tree\n",
    "    model = RandomForestClassifier(random_state=0)  # Random forest classifier\n",
    "    return Pipeline(steps=[('feature_selection', rfe), ('classifier', model)])  # Pipeline combining feature selection and classification\n",
    "\n",
    "def get_param_grid():\n",
    "    \"\"\"Returns the hyperparameter grid for GridSearchCV.\"\"\"\n",
    "    return {\n",
    "        'classifier__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "        'classifier__class_weight': [{0: 0.75, 1: 1.48}, None],  # Class weights\n",
    "        'classifier__max_depth': [None, 10, 20],  # Maximum depth of the tree\n",
    "        'feature_selection__n_features_to_select': [5, 10, 20, 40, 80]  # Number of features to select with RFE\n",
    "    }\n",
    "\n",
    "def perform_nested_cv(X, y, random_state=0):\n",
    "    \"\"\"Performs nested cross-validation and returns the test scores.\"\"\"\n",
    "    # Define the inner and outer cross-validation strategies\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    outer_cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    pipeline = build_pipeline()  # Build the pipeline\n",
    "    param_grid = get_param_grid()  # Get the hyperparameter grid\n",
    "    \n",
    "    # Perform grid search with cross-validation\n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=inner_cv, n_jobs=2)\n",
    "    # Perform nested cross-validation\n",
    "    cv_results = cross_validate(grid_search, X, y, cv=outer_cv, n_jobs=2, return_estimator=True, return_train_score=True)\n",
    "    \n",
    "    test_scores = cv_results['test_score']  # Extract test scores\n",
    "    test_score_mean = test_scores.mean()  # Calculate mean test score\n",
    "    test_score_std = test_scores.std()  # Calculate standard deviation of test scores\n",
    "    \n",
    "    print(f\"Test scores for each fold: {test_scores}\")\n",
    "    \n",
    "    for idx, score in enumerate(test_scores):\n",
    "        print(f\"Fold {idx + 1} score: {score:.3f}, SD: {test_score_std:.3f}\")  # Print score and SD for each fold\n",
    "    \n",
    "    print(f\"The mean score using nested cross-validation is: {test_score_mean:.3f} ± {test_score_std:.3f}\")\n",
    "    \n",
    "    # Print the best parameters for each fold\n",
    "    for idx, result in enumerate(cv_results['estimator']):\n",
    "        print(f\"Fold {idx + 1} best parameters: {result.best_params_}\")\n",
    "    \n",
    "    return cv_results\n",
    "\n",
    "def plot_curves(y_test, y_proba, y_pred):\n",
    "    \"\"\"Plots PR and ROC curves.\"\"\"\n",
    "    # Plot Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f'Precision-Recall curve (AUC = {auc_pr:.3f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_roc:.3f})')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(cv_results, X_test, y_test):\n",
    "    \"\"\"Evaluates the model on the test set.\"\"\"\n",
    "    best_estimator_per_fold = [result.best_estimator_ for result in cv_results['estimator']]  # Get best estimator for each fold\n",
    "    \n",
    "    # Evaluate the best model on the test set\n",
    "    best_model = best_estimator_per_fold[np.argmax(cv_results['test_score'])]  # Select the best model based on test scores\n",
    "    \n",
    "    print(\"\\nEvaluating best model on test set\")\n",
    "    y_test_pred = best_model.predict(X_test)  # Predict on the test set\n",
    "    \n",
    "    print(\"\\nClassification Report on Test Set:\")\n",
    "    print(classification_report(y_test, y_test_pred))  # Print classification report\n",
    "    print(confusion_matrix(y_test, y_test_pred))  # Print confusion matrix\n",
    "    \n",
    "    y_test_proba = best_model.predict_proba(X_test)[:, 1]  # Get prediction probabilities\n",
    "    plot_curves(y_test, y_test_proba, y_test_pred)  # Plot PR and ROC curves\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_test_proba)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    print(f\"Test AUC-PR: {auc_pr:.3f}\")  # Print AUC-PR score\n",
    "\n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "\n",
    "cv_results = perform_nested_cv(X_train, y_train, random_state=random_seed)  # Perform nested cross-validation\n",
    "y_test_pred = evaluate_model(cv_results, X_test, y_test)  # Evaluate the model on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_4/nzq6mygj7j71_l3z_c9kc7wr0000gn/T/ipykernel_18152/3478761178.py:12: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-darkgrid')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "font = 'Times New Roman'\n",
    "size = 18\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Set the style to a modern style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Create a custom diverging color map\n",
    "colors = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=colors, cbar=False,\n",
    "            annot_kws={'fontname': font, 'fontsize': size})  # Set font and size for numbers\n",
    "plt.title('Random Forest - Combination', fontname=font, fontsize=size)\n",
    "plt.xlabel('Predicted', fontname=font, fontsize=size)\n",
    "plt.ylabel('Actual', fontname=font, fontsize=size)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
