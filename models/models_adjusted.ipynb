{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models NOT YET ADJUSTED "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, auc, precision_recall_curve, confusion_matrix\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sum_12</th>\n",
       "      <th>sum_4567</th>\n",
       "      <th>sum_456</th>\n",
       "      <th>VVR_group</th>\n",
       "      <th>Condition</th>\n",
       "      <th>VVR_1</th>\n",
       "      <th>VVR_2</th>\n",
       "      <th>AU01_r__sum_values</th>\n",
       "      <th>AU01_r__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_r__minimum</th>\n",
       "      <th>AU26_r__mean</th>\n",
       "      <th>AU26_r__mean_abs_change</th>\n",
       "      <th>AU45_r__sum_values</th>\n",
       "      <th>AU45_r__variance</th>\n",
       "      <th>AU45_r__standard_deviation</th>\n",
       "      <th>AU45_r__maximum</th>\n",
       "      <th>AU45_r__minimum</th>\n",
       "      <th>AU45_r__mean</th>\n",
       "      <th>AU45_r__mean_abs_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>24.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4982.48</td>\n",
       "      <td>0.425041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.633284</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>9231.74</td>\n",
       "      <td>0.825039</td>\n",
       "      <td>0.908316</td>\n",
       "      <td>4.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.627753</td>\n",
       "      <td>0.133624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9390.23</td>\n",
       "      <td>0.448366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.484701</td>\n",
       "      <td>0.125851</td>\n",
       "      <td>11887.00</td>\n",
       "      <td>0.634554</td>\n",
       "      <td>0.796589</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.436942</td>\n",
       "      <td>0.098134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>28.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6954.35</td>\n",
       "      <td>0.599805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.862301</td>\n",
       "      <td>0.101969</td>\n",
       "      <td>9020.78</td>\n",
       "      <td>0.750701</td>\n",
       "      <td>0.866430</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.550652</td>\n",
       "      <td>0.085720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9707.43</td>\n",
       "      <td>0.873280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.552359</td>\n",
       "      <td>0.069582</td>\n",
       "      <td>6585.31</td>\n",
       "      <td>0.609348</td>\n",
       "      <td>0.780607</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.371673</td>\n",
       "      <td>0.056287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21049.90</td>\n",
       "      <td>1.475421</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>0.142027</td>\n",
       "      <td>0.386527</td>\n",
       "      <td>23027.73</td>\n",
       "      <td>1.160635</td>\n",
       "      <td>1.077328</td>\n",
       "      <td>5.04</td>\n",
       "      <td>-4.29</td>\n",
       "      <td>1.094318</td>\n",
       "      <td>0.231853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  sum_12  sum_4567  sum_456  VVR_group  Condition  VVR_1  VVR_2  \\\n",
       "0  23    24.0      37.0     27.0          0          2   13.0   11.0   \n",
       "1  24    23.0      37.0     28.0          0          2   12.0   11.0   \n",
       "2  25    28.0      44.0     33.0          1          2   16.0   12.0   \n",
       "3  26    30.0      37.0     29.0          0          1   15.0   15.0   \n",
       "4  27    22.0      39.0     31.0          1          2   11.0   11.0   \n",
       "\n",
       "   AU01_r__sum_values  AU01_r__variance  ...  AU26_r__minimum  AU26_r__mean  \\\n",
       "0             4982.48          0.425041  ...             0.00      0.633284   \n",
       "1             9390.23          0.448366  ...             0.00      1.484701   \n",
       "2             6954.35          0.599805  ...             0.00      0.862301   \n",
       "3             9707.43          0.873280  ...             0.00      0.552359   \n",
       "4            21049.90          1.475421  ...            -3.92      0.142027   \n",
       "\n",
       "   AU26_r__mean_abs_change  AU45_r__sum_values  AU45_r__variance  \\\n",
       "0                 0.076328             9231.74          0.825039   \n",
       "1                 0.125851            11887.00          0.634554   \n",
       "2                 0.101969             9020.78          0.750701   \n",
       "3                 0.069582             6585.31          0.609348   \n",
       "4                 0.386527            23027.73          1.160635   \n",
       "\n",
       "   AU45_r__standard_deviation  AU45_r__maximum  AU45_r__minimum  AU45_r__mean  \\\n",
       "0                    0.908316             4.91             0.00      0.627753   \n",
       "1                    0.796589             5.00             0.00      0.436942   \n",
       "2                    0.866430             4.04             0.00      0.550652   \n",
       "3                    0.780607             4.90             0.00      0.371673   \n",
       "4                    1.077328             5.04            -4.29      1.094318   \n",
       "\n",
       "   AU45_r__mean_abs_change  \n",
       "0                 0.133624  \n",
       "1                 0.098134  \n",
       "2                 0.085720  \n",
       "3                 0.056287  \n",
       "4                 0.231853  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df = pd.read_csv('/Users/dionnespaltman/Desktop/V3/merged_df.csv', sep=',')\n",
    "\n",
    "merged_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "merged_df.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
    "\n",
    "display(merged_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in VVR_group = 1: 26\n",
      "Number of instances in VVR_group = 0: 85\n"
     ]
    }
   ],
   "source": [
    "# Count the number of instances of people in VVR_group = 1 and VVR_group = 0\n",
    "count_vvr_group = merged_df['VVR_group'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of instances in VVR_group = 1:\", count_vvr_group[1])\n",
    "print(\"Number of instances in VVR_group = 0:\", count_vvr_group[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dionnespaltman/Desktop/V3/columns_action_units.json', 'r') as f:\n",
    "    columns_action_units = json.load(f)\n",
    "\n",
    "print(len(columns_action_units))\n",
    "# print(columns_action_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy = make_pipeline(featurizer, DummyClassifier(strategy='most_frequent'))\n",
    "# rf = make_pipeline(featurizer, RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0))\n",
    "# svm = make_pipeline(featurizer, SVC())\n",
    "# multiclass_svm = make_pipeline(featurizer, SVC(decision_function_shape='ovr'))\n",
    "# xgb = make_pipeline(featurizer, XGBClassifier())\n",
    "# mlp = make_pipeline(featurizer, MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000))\n",
    "\n",
    "# models = {\n",
    "#     \"Dummy\": dummy,\n",
    "#     \"RandomForest\": rf,\n",
    "#     \"SVM\": svm,\n",
    "#     \"Multiclass SVM\": multiclass_svm,\n",
    "#     \"XGBoost\": xgb,\n",
    "#     \"MLP\": mlp\n",
    "# }\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dummy = make_pipeline(featurizer, DummyClassifier(strategy='most_frequent'))\n",
    "rf = make_pipeline(featurizer, RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0))\n",
    "svm = make_pipeline(featurizer, SVC())\n",
    "multiclass_svm = make_pipeline(featurizer, SVC(decision_function_shape='ovr'))\n",
    "xgb = make_pipeline(featurizer, XGBClassifier())\n",
    "mlp = make_pipeline(featurizer, MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000))\n",
    "decision_tree = make_pipeline(featurizer, DecisionTreeClassifier())\n",
    "\n",
    "models = {\n",
    "    \"Dummy\": dummy,\n",
    "    \"RandomForest\": rf,\n",
    "    \"SVM\": svm,\n",
    "    \"Multiclass SVM\": multiclass_svm,\n",
    "    \"XGBoost\": xgb,\n",
    "    \"MLP\": mlp,\n",
    "    \"DecisionTree\": decision_tree\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_model(model, X, y):\n",
    "#     \"\"\"\n",
    "#     Evaluate the model's performance\n",
    "#     \"\"\"\n",
    "#     model.fit(X, y)\n",
    "#     y_probs = model.predict_proba(X)[:, 1]\n",
    "#     precision = precision_score(y, model.predict(X))\n",
    "#     recall = recall_score(y, model.predict(X))\n",
    "#     f1 = f1_score(y, model.predict(X))\n",
    "#     precision_curve, recall_curve, _ = precision_recall_curve(y, y_probs)\n",
    "#     auc_pr = auc(recall_curve, precision_curve)\n",
    "#     cm = confusion_matrix(y, model.predict(X))\n",
    "    \n",
    "#     logging.info(f\"Precision: {precision}\")\n",
    "#     logging.info(f\"Recall: {recall}\")\n",
    "#     logging.info(f\"F1-score: {f1}\")\n",
    "#     logging.info(f\"AUC-PR score: {auc_pr}\")\n",
    "#     logging.info(f\"Confusion Matrix:\")\n",
    "#     logging.info(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "10800 fits failed out of a total of 32400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5304 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5496 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.80619048 0.82571429 0.83571429]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': 5, 'max_features': 'log2', 'max_leaf_nodes': 20, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Accuracy on Validation Data: 0.8235294117647058\n",
      "AUC-PR on Validation Data: 0.8623949579831932\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        18\n",
      "           1       0.86      0.75      0.80        16\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.83      0.82      0.82        34\n",
      "weighted avg       0.83      0.82      0.82        34\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 10, 20, 30],\n",
    "    'min_impurity_decrease': [0.0, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "# Instantiate the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "# Create the grid search object\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(train.drop('VVR_group', axis=1), train['VVR_group'].values)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Use the best estimator to make predictions\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the validation set using the best estimator\n",
    "pred = best_rf.predict(val.drop('VVR_group', axis=1))\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val['VVR_group'].values, pred)\n",
    "report = classification_report(val['VVR_group'].values, pred)\n",
    "precision, recall, _ = precision_recall_curve(val['VVR_group'].values, pred)\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy on Validation Data: {accuracy}\")\n",
    "print(f\"AUC-PR on Validation Data: {auc_pr}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fitting models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating Dummy on validation data\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "INFO:root:Dummy Accuracy: 0.5294117647058824\n",
      "INFO:root:Dummy AUC-PR: 0.7352941176470589\n",
      "INFO:root:Dummy Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69        18\n",
      "           1       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.53        34\n",
      "   macro avg       0.26      0.50      0.35        34\n",
      "weighted avg       0.28      0.53      0.37        34\n",
      "\n",
      "INFO:root:Dummy Confusion Matrix:\n",
      "INFO:root:<function confusion_matrix at 0x7fbba315da20>\n",
      "INFO:root:Evaluating RandomForest on validation data\n",
      "INFO:root:RandomForest Accuracy: 0.8823529411764706\n",
      "INFO:root:RandomForest AUC-PR: 0.9044117647058824\n",
      "INFO:root:RandomForest Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        18\n",
      "           1       0.88      0.88      0.88        16\n",
      "\n",
      "    accuracy                           0.88        34\n",
      "   macro avg       0.88      0.88      0.88        34\n",
      "weighted avg       0.88      0.88      0.88        34\n",
      "\n",
      "INFO:root:RandomForest Confusion Matrix:\n",
      "INFO:root:<function confusion_matrix at 0x7fbba315da20>\n",
      "INFO:root:Evaluating SVM on validation data\n",
      "INFO:root:SVM Accuracy: 0.7941176470588235\n",
      "INFO:root:SVM AUC-PR: 0.8338235294117647\n",
      "INFO:root:SVM Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81        18\n",
      "           1       0.80      0.75      0.77        16\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.79      0.79      0.79        34\n",
      "weighted avg       0.79      0.79      0.79        34\n",
      "\n",
      "INFO:root:SVM Confusion Matrix:\n",
      "INFO:root:<function confusion_matrix at 0x7fbba315da20>\n",
      "INFO:root:Evaluating Multiclass SVM on validation data\n",
      "INFO:root:Multiclass SVM Accuracy: 0.7941176470588235\n",
      "INFO:root:Multiclass SVM AUC-PR: 0.8338235294117647\n",
      "INFO:root:Multiclass SVM Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81        18\n",
      "           1       0.80      0.75      0.77        16\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.79      0.79      0.79        34\n",
      "weighted avg       0.79      0.79      0.79        34\n",
      "\n",
      "INFO:root:Multiclass SVM Confusion Matrix:\n",
      "INFO:root:<function confusion_matrix at 0x7fbba315da20>\n",
      "INFO:root:Evaluating XGBoost on validation data\n",
      "INFO:root:XGBoost Accuracy: 0.8529411764705882\n",
      "INFO:root:XGBoost AUC-PR: 0.8809523809523809\n",
      "INFO:root:XGBoost Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        18\n",
      "           1       0.76      1.00      0.86        16\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.88      0.86      0.85        34\n",
      "weighted avg       0.89      0.85      0.85        34\n",
      "\n",
      "INFO:root:XGBoost Confusion Matrix:\n",
      "INFO:root:<function confusion_matrix at 0x7fbba315da20>\n",
      "INFO:root:Evaluating MLP on validation data\n",
      "INFO:root:MLP Accuracy: 0.8235294117647058\n",
      "INFO:root:MLP AUC-PR: 0.8566176470588236\n",
      "INFO:root:MLP Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83        18\n",
      "           1       0.81      0.81      0.81        16\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.82      0.82      0.82        34\n",
      "weighted avg       0.82      0.82      0.82        34\n",
      "\n",
      "INFO:root:MLP Confusion Matrix:\n",
      "INFO:root:<function confusion_matrix at 0x7fbba315da20>\n",
      "INFO:root:Evaluating DecisionTree on validation data\n",
      "INFO:root:DecisionTree Accuracy: 0.7647058823529411\n",
      "INFO:root:DecisionTree AUC-PR: 0.8169117647058823\n",
      "INFO:root:DecisionTree Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75        18\n",
      "           1       0.70      0.88      0.78        16\n",
      "\n",
      "    accuracy                           0.76        34\n",
      "   macro avg       0.78      0.77      0.76        34\n",
      "weighted avg       0.78      0.76      0.76        34\n",
      "\n",
      "INFO:root:DecisionTree Confusion Matrix:\n",
      "INFO:root:<function confusion_matrix at 0x7fbba315da20>\n",
      "INFO:root:Predicting on test using best model: RandomForest\n",
      "INFO:root:RandomForest Accuracy on Test Data: 0.7941176470588235\n",
      "INFO:root:RandomForest Classification Report on Test Data:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72        12\n",
      "           1       0.86      0.82      0.84        22\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.77      0.78      0.78        34\n",
      "weighted avg       0.80      0.79      0.80        34\n",
      "\n",
      "INFO:root:RandomForest Confusion Matrix:\n",
      "INFO:root:[[ 9  3]\n",
      " [ 4 18]]\n"
     ]
    }
   ],
   "source": [
    "# Set logging level to INFO\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# merged_df = load_data()\n",
    "# train, val, test = split_data(merged_df)\n",
    "# columns_action_units = load_columns()\n",
    "# featurizer = define_featurizer(columns_action_units)\n",
    "# models = define_models(featurizer)\n",
    "\n",
    "# logging.info(\"Applying SMOTE to handle class imbalance\")\n",
    "# sm = SMOTE(random_state=42)\n",
    "# X_res, y_res = sm.fit_resample(train.drop('VVR_group', axis=1), train['VVR_group'].values)\n",
    "# logging.info(\"X_res, y_res:\", X_res.shape, y_res.shape)\n",
    "# train_resampled = pd.DataFrame(X_res, columns=train.drop('VVR_group', axis=1).columns)\n",
    "# train_resampled['VVR_group'] = y_res\n",
    "\n",
    "logging.info(\"Fitting models\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(train.drop('VVR_group', axis=1), train['VVR_group'].values)\n",
    "    logging.info(f\"Evaluating {name} on validation data\")\n",
    "    pred = model.predict(val.drop('VVR_group', axis=1))\n",
    "    accuracy = accuracy_score(val['VVR_group'].values, pred)\n",
    "    report = classification_report(val['VVR_group'].values, pred)\n",
    "    \n",
    "    # Calculating Precision-Recall curve and its AUC\n",
    "    precision, recall, _ = precision_recall_curve(val['VVR_group'].values, pred)\n",
    "    auc_pr = auc(recall, precision)\n",
    "\n",
    "    logging.info(f\"{name} Accuracy: {accuracy}\")\n",
    "    logging.info(f\"{name} AUC-PR: {auc_pr}\")  # Including AUC-PR in logging\n",
    "    logging.info(f\"{name} Classification Report:\")\n",
    "    logging.info(report)\n",
    "    logging.info(f\"{name} Confusion Matrix:\")\n",
    "    logging.info(cm)\n",
    "\n",
    "best_model_name = max(models, key=lambda x: accuracy_score(val['VVR_group'].values, models[x].predict(val.drop('VVR_group', axis=1))))\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "logging.info(f\"Predicting on test using best model: {best_model_name}\")\n",
    "\n",
    "pred = best_model.predict(test.drop('VVR_group', axis=1))\n",
    "\n",
    "accuracy = accuracy_score(test['VVR_group'].values, pred)\n",
    "report = classification_report(test['VVR_group'].values, pred)\n",
    "cm = confusion_matrix(test['VVR_group'].values, pred)\n",
    "\n",
    "logging.info(f\"{best_model_name} Accuracy on Test Data: {accuracy}\")\n",
    "logging.info(f\"{best_model_name} Classification Report on Test Data:\")\n",
    "logging.info(report)\n",
    "logging.info(f\"{best_model_name} Confusion Matrix:\")\n",
    "logging.info(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
