{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add description. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, auc, precision_recall_curve, confusion_matrix\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_res:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VVR_1</th>\n",
       "      <th>VVR_2</th>\n",
       "      <th>AU01_r__sum_values</th>\n",
       "      <th>AU01_r__variance</th>\n",
       "      <th>AU01_r__standard_deviation</th>\n",
       "      <th>AU01_r__maximum</th>\n",
       "      <th>AU01_r__mean</th>\n",
       "      <th>AU01_r__root_mean_square</th>\n",
       "      <th>AU02_r__sum_values</th>\n",
       "      <th>AU02_r__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_r__standard_deviation</th>\n",
       "      <th>AU26_r__maximum</th>\n",
       "      <th>AU26_r__mean</th>\n",
       "      <th>AU26_r__root_mean_square</th>\n",
       "      <th>AU45_r__sum_values</th>\n",
       "      <th>AU45_r__variance</th>\n",
       "      <th>AU45_r__standard_deviation</th>\n",
       "      <th>AU45_r__maximum</th>\n",
       "      <th>AU45_r__mean</th>\n",
       "      <th>AU45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.070220</td>\n",
       "      <td>-0.403569</td>\n",
       "      <td>-0.161650</td>\n",
       "      <td>0.428359</td>\n",
       "      <td>-0.673859</td>\n",
       "      <td>-0.387663</td>\n",
       "      <td>0.994371</td>\n",
       "      <td>0.345623</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.537730</td>\n",
       "      <td>0.225549</td>\n",
       "      <td>-1.036133</td>\n",
       "      <td>-0.951754</td>\n",
       "      <td>-1.025247</td>\n",
       "      <td>-1.526773</td>\n",
       "      <td>-1.479742</td>\n",
       "      <td>-1.237893</td>\n",
       "      <td>-2.161830</td>\n",
       "      <td>-2.049390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.226447</td>\n",
       "      <td>1.288304</td>\n",
       "      <td>1.124217</td>\n",
       "      <td>0.514376</td>\n",
       "      <td>0.729448</td>\n",
       "      <td>1.091318</td>\n",
       "      <td>3.433959</td>\n",
       "      <td>2.208680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774622</td>\n",
       "      <td>0.458331</td>\n",
       "      <td>0.368352</td>\n",
       "      <td>0.632011</td>\n",
       "      <td>1.209277</td>\n",
       "      <td>-0.225126</td>\n",
       "      <td>-0.001447</td>\n",
       "      <td>0.619766</td>\n",
       "      <td>-0.202961</td>\n",
       "      <td>-0.127515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.328541</td>\n",
       "      <td>-0.286339</td>\n",
       "      <td>-0.049149</td>\n",
       "      <td>0.514376</td>\n",
       "      <td>-0.191466</td>\n",
       "      <td>-0.152619</td>\n",
       "      <td>-0.351110</td>\n",
       "      <td>-0.286124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539267</td>\n",
       "      <td>0.408449</td>\n",
       "      <td>0.316323</td>\n",
       "      <td>0.450683</td>\n",
       "      <td>-0.834081</td>\n",
       "      <td>-0.909004</td>\n",
       "      <td>-0.642000</td>\n",
       "      <td>0.297037</td>\n",
       "      <td>-1.125698</td>\n",
       "      <td>-0.981679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.179816</td>\n",
       "      <td>1.024130</td>\n",
       "      <td>0.956659</td>\n",
       "      <td>0.514376</td>\n",
       "      <td>0.292720</td>\n",
       "      <td>0.824388</td>\n",
       "      <td>-0.176376</td>\n",
       "      <td>0.226388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891064</td>\n",
       "      <td>0.458331</td>\n",
       "      <td>0.480862</td>\n",
       "      <td>0.766552</td>\n",
       "      <td>-0.208294</td>\n",
       "      <td>0.810246</td>\n",
       "      <td>0.749643</td>\n",
       "      <td>0.257680</td>\n",
       "      <td>0.422548</td>\n",
       "      <td>0.743912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.687261</td>\n",
       "      <td>-0.791730</td>\n",
       "      <td>-0.584920</td>\n",
       "      <td>0.514376</td>\n",
       "      <td>-0.763173</td>\n",
       "      <td>-0.767495</td>\n",
       "      <td>-0.530851</td>\n",
       "      <td>-0.455929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.558621</td>\n",
       "      <td>0.366881</td>\n",
       "      <td>-0.858611</td>\n",
       "      <td>-0.877156</td>\n",
       "      <td>-0.419249</td>\n",
       "      <td>-0.490562</td>\n",
       "      <td>-0.230352</td>\n",
       "      <td>-0.340549</td>\n",
       "      <td>-0.573360</td>\n",
       "      <td>-0.444615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VVR_1  VVR_2  AU01_r__sum_values  AU01_r__variance  \\\n",
       "0   12.0   13.0           -0.070220         -0.403569   \n",
       "1   10.0   10.0            2.226447          1.288304   \n",
       "2    8.0    8.0           -0.328541         -0.286339   \n",
       "3   10.0    8.0           -0.179816          1.024130   \n",
       "4    8.0    8.0           -0.687261         -0.791730   \n",
       "\n",
       "   AU01_r__standard_deviation  AU01_r__maximum  AU01_r__mean  \\\n",
       "0                   -0.161650         0.428359     -0.673859   \n",
       "1                    1.124217         0.514376      0.729448   \n",
       "2                   -0.049149         0.514376     -0.191466   \n",
       "3                    0.956659         0.514376      0.292720   \n",
       "4                   -0.584920         0.514376     -0.763173   \n",
       "\n",
       "   AU01_r__root_mean_square  AU02_r__sum_values  AU02_r__variance  ...  \\\n",
       "0                 -0.387663            0.994371          0.345623  ...   \n",
       "1                  1.091318            3.433959          2.208680  ...   \n",
       "2                 -0.152619           -0.351110         -0.286124  ...   \n",
       "3                  0.824388           -0.176376          0.226388  ...   \n",
       "4                 -0.767495           -0.530851         -0.455929  ...   \n",
       "\n",
       "   AU26_r__standard_deviation  AU26_r__maximum  AU26_r__mean  \\\n",
       "0                   -0.537730         0.225549     -1.036133   \n",
       "1                    0.774622         0.458331      0.368352   \n",
       "2                    0.539267         0.408449      0.316323   \n",
       "3                    0.891064         0.458331      0.480862   \n",
       "4                   -0.558621         0.366881     -0.858611   \n",
       "\n",
       "   AU26_r__root_mean_square  AU45_r__sum_values  AU45_r__variance  \\\n",
       "0                 -0.951754           -1.025247         -1.526773   \n",
       "1                  0.632011            1.209277         -0.225126   \n",
       "2                  0.450683           -0.834081         -0.909004   \n",
       "3                  0.766552           -0.208294          0.810246   \n",
       "4                 -0.877156           -0.419249         -0.490562   \n",
       "\n",
       "   AU45_r__standard_deviation  AU45_r__maximum  AU45_r__mean  \\\n",
       "0                   -1.479742        -1.237893     -2.161830   \n",
       "1                   -0.001447         0.619766     -0.202961   \n",
       "2                   -0.642000         0.297037     -1.125698   \n",
       "3                    0.749643         0.257680      0.422548   \n",
       "4                   -0.230352        -0.340549     -0.573360   \n",
       "\n",
       "   AU45_r__root_mean_square  \n",
       "0                 -2.049390  \n",
       "1                 -0.127515  \n",
       "2                 -0.981679  \n",
       "3                  0.743912  \n",
       "4                 -0.444615  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train_res:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VVR_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VVR_group\n",
       "0          1\n",
       "1          1\n",
       "2          0\n",
       "3          0\n",
       "4          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VVR_1</th>\n",
       "      <th>VVR_2</th>\n",
       "      <th>AU01_r__sum_values</th>\n",
       "      <th>AU01_r__variance</th>\n",
       "      <th>AU01_r__standard_deviation</th>\n",
       "      <th>AU01_r__maximum</th>\n",
       "      <th>AU01_r__mean</th>\n",
       "      <th>AU01_r__root_mean_square</th>\n",
       "      <th>AU02_r__sum_values</th>\n",
       "      <th>AU02_r__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_r__standard_deviation</th>\n",
       "      <th>AU26_r__maximum</th>\n",
       "      <th>AU26_r__mean</th>\n",
       "      <th>AU26_r__root_mean_square</th>\n",
       "      <th>AU45_r__sum_values</th>\n",
       "      <th>AU45_r__variance</th>\n",
       "      <th>AU45_r__standard_deviation</th>\n",
       "      <th>AU45_r__maximum</th>\n",
       "      <th>AU45_r__mean</th>\n",
       "      <th>AU45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-1.088267</td>\n",
       "      <td>-0.486929</td>\n",
       "      <td>-0.245322</td>\n",
       "      <td>-0.094909</td>\n",
       "      <td>-0.387079</td>\n",
       "      <td>-0.373556</td>\n",
       "      <td>-0.296967</td>\n",
       "      <td>1.267608</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.106604</td>\n",
       "      <td>-1.661648</td>\n",
       "      <td>-0.939358</td>\n",
       "      <td>-1.258986</td>\n",
       "      <td>-0.862599</td>\n",
       "      <td>0.657150</td>\n",
       "      <td>0.649175</td>\n",
       "      <td>0.619766</td>\n",
       "      <td>0.540339</td>\n",
       "      <td>0.684272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.160204</td>\n",
       "      <td>0.681681</td>\n",
       "      <td>0.725849</td>\n",
       "      <td>0.514376</td>\n",
       "      <td>0.751085</td>\n",
       "      <td>0.775827</td>\n",
       "      <td>0.031562</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791290</td>\n",
       "      <td>0.458331</td>\n",
       "      <td>1.507769</td>\n",
       "      <td>1.887518</td>\n",
       "      <td>-0.111414</td>\n",
       "      <td>0.662918</td>\n",
       "      <td>0.653014</td>\n",
       "      <td>0.478080</td>\n",
       "      <td>0.552052</td>\n",
       "      <td>0.691181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.510947</td>\n",
       "      <td>-0.678086</td>\n",
       "      <td>-0.451146</td>\n",
       "      <td>-0.130749</td>\n",
       "      <td>-0.740730</td>\n",
       "      <td>-0.650167</td>\n",
       "      <td>-0.512662</td>\n",
       "      <td>-0.414737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412202</td>\n",
       "      <td>0.458331</td>\n",
       "      <td>-0.395816</td>\n",
       "      <td>0.012935</td>\n",
       "      <td>0.703933</td>\n",
       "      <td>1.133047</td>\n",
       "      <td>0.952462</td>\n",
       "      <td>0.619766</td>\n",
       "      <td>0.765365</td>\n",
       "      <td>1.028129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.139765</td>\n",
       "      <td>0.115481</td>\n",
       "      <td>0.300321</td>\n",
       "      <td>0.406855</td>\n",
       "      <td>0.152945</td>\n",
       "      <td>0.239720</td>\n",
       "      <td>0.621775</td>\n",
       "      <td>-0.239594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009577</td>\n",
       "      <td>0.017708</td>\n",
       "      <td>-0.227168</td>\n",
       "      <td>-0.190216</td>\n",
       "      <td>1.476715</td>\n",
       "      <td>0.191834</td>\n",
       "      <td>0.323467</td>\n",
       "      <td>0.493823</td>\n",
       "      <td>0.412243</td>\n",
       "      <td>0.350324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.257027</td>\n",
       "      <td>1.622690</td>\n",
       "      <td>1.325337</td>\n",
       "      <td>0.514376</td>\n",
       "      <td>1.084273</td>\n",
       "      <td>1.365502</td>\n",
       "      <td>1.155021</td>\n",
       "      <td>1.601645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075374</td>\n",
       "      <td>0.217235</td>\n",
       "      <td>-0.256234</td>\n",
       "      <td>-0.149869</td>\n",
       "      <td>-0.194813</td>\n",
       "      <td>-0.655535</td>\n",
       "      <td>-0.383937</td>\n",
       "      <td>-0.104406</td>\n",
       "      <td>-0.685164</td>\n",
       "      <td>-0.617897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VVR_1  VVR_2  AU01_r__sum_values  AU01_r__variance  \\\n",
       "0   10.0   11.0           -1.088267         -0.486929   \n",
       "1   19.0   21.0            0.160204          0.681681   \n",
       "2    8.0    8.0           -0.510947         -0.678086   \n",
       "3   21.0   21.0            1.139765          0.115481   \n",
       "4   11.0    8.0            1.257027          1.622690   \n",
       "\n",
       "   AU01_r__standard_deviation  AU01_r__maximum  AU01_r__mean  \\\n",
       "0                   -0.245322        -0.094909     -0.387079   \n",
       "1                    0.725849         0.514376      0.751085   \n",
       "2                   -0.451146        -0.130749     -0.740730   \n",
       "3                    0.300321         0.406855      0.152945   \n",
       "4                    1.325337         0.514376      1.084273   \n",
       "\n",
       "   AU01_r__root_mean_square  AU02_r__sum_values  AU02_r__variance  ...  \\\n",
       "0                 -0.373556           -0.296967          1.267608  ...   \n",
       "1                  0.775827            0.031562          0.457413  ...   \n",
       "2                 -0.650167           -0.512662         -0.414737  ...   \n",
       "3                  0.239720            0.621775         -0.239594  ...   \n",
       "4                  1.365502            1.155021          1.601645  ...   \n",
       "\n",
       "   AU26_r__standard_deviation  AU26_r__maximum  AU26_r__mean  \\\n",
       "0                   -1.106604        -1.661648     -0.939358   \n",
       "1                    1.791290         0.458331      1.507769   \n",
       "2                    0.412202         0.458331     -0.395816   \n",
       "3                   -0.009577         0.017708     -0.227168   \n",
       "4                    0.075374         0.217235     -0.256234   \n",
       "\n",
       "   AU26_r__root_mean_square  AU45_r__sum_values  AU45_r__variance  \\\n",
       "0                 -1.258986           -0.862599          0.657150   \n",
       "1                  1.887518           -0.111414          0.662918   \n",
       "2                  0.012935            0.703933          1.133047   \n",
       "3                 -0.190216            1.476715          0.191834   \n",
       "4                 -0.149869           -0.194813         -0.655535   \n",
       "\n",
       "   AU45_r__standard_deviation  AU45_r__maximum  AU45_r__mean  \\\n",
       "0                    0.649175         0.619766      0.540339   \n",
       "1                    0.653014         0.478080      0.552052   \n",
       "2                    0.952462         0.619766      0.765365   \n",
       "3                    0.323467         0.493823      0.412243   \n",
       "4                   -0.383937        -0.104406     -0.685164   \n",
       "\n",
       "   AU45_r__root_mean_square  \n",
       "0                  0.684272  \n",
       "1                  0.691181  \n",
       "2                  1.028129  \n",
       "3                  0.350324  \n",
       "4                 -0.617897  \n",
       "\n",
       "[5 rows x 104 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VVR_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VVR_group\n",
       "0          0\n",
       "1          1\n",
       "2          0\n",
       "3          1\n",
       "4          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data into pandas dataframes\n",
    "X_train_res = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/X_train_res.csv')\n",
    "y_train_res = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/y_train_res.csv')\n",
    "X_test = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/X_test.csv')\n",
    "y_test = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/y_test.csv')\n",
    "\n",
    "X_train_res = X_train_res.drop(columns='Unnamed: 0', axis=1)\n",
    "y_train_res = y_train_res.drop(columns='Unnamed: 0', axis=1)\n",
    "X_test = X_test.drop(columns='Unnamed: 0', axis=1)\n",
    "y_test = y_test.drop(columns='Unnamed: 0', axis=1)\n",
    "\n",
    "# Convert the DataFrame to a NumPy array\n",
    "# y_test = y_test.to_numpy()\n",
    "\n",
    "# Display the first few rows of each dataframe to verify the loading\n",
    "print(\"X_train_res:\")\n",
    "display(X_train_res.head())\n",
    "\n",
    "print(\"\\ny_train_res:\")\n",
    "display(y_train_res.head())\n",
    "\n",
    "print(\"\\nX_test:\")\n",
    "display(X_test.head())\n",
    "\n",
    "print(\"\\ny_test:\")\n",
    "# print(y_test)\n",
    "display(y_test.head())\n",
    "\n",
    "# Convert the DataFrame to a 1-dimensional NumPy array\n",
    "y_train_res = y_train_res.values.ravel()\n",
    "y_test = y_test.values.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (not complete but a intermediate step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strange enough the recall is much higher (0.27 instead of 0.18) when I don't use class weights. \n",
    "\n",
    "The model you can see here is not using K-fold cross validation. \n",
    "\n",
    "Here I haven't done any Recursive Feature Analysis or cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Validation Data: 0.78125\n",
      "AUC-PR on Validation Data: 0.4709821428571429\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87        25\n",
      "           1       0.50      0.29      0.36         7\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.66      0.60      0.62        32\n",
      "weighted avg       0.75      0.78      0.76        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "from collections import Counter\n",
    "\n",
    "# Train the RandomForestClassifier directly on the resampled training data\n",
    "rf_classifier = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0)\n",
    "rf_classifier.fit(X_train_res, y_train_res)\n",
    "\n",
    "columns_to_drop = [ 'ID', 'Sum_12', 'Sum_4567', 'Sum_456', 'VVR_group', 'Condition', 'Date', 'Gender'] \n",
    "\n",
    "# Predict on the test data\n",
    "pred = rf_classifier.predict(test.drop(columns=columns_to_drop, axis=1))\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(test['VVR_group'].values, pred)\n",
    "report = classification_report(test['VVR_group'].values, pred)\n",
    "cm = confusion_matrix(test['VVR_group'].values, pred)\n",
    "precision, recall, _ = precision_recall_curve(test['VVR_group'].values, pred)\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy on Validation Data: {accuracy}\")\n",
    "print(f\"AUC-PR on Validation Data: {auc_pr}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive feature elimination to optimize the scores - not using SMOTE\n",
    "\n",
    "I based my code partially on the following article: \n",
    "https://machinelearningmastery.com/rfe-feature-selection-in-python/\n",
    "\n",
    "Here I did apply cross validation, but not yet with hyperparameter tuning, so it's not the final model yet. \n",
    "\n",
    "For this step we don't use SMOTE because you can't specify what the test and train set is. So here I make a X and y and use this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.899 (0.127)\n",
      "Selected Features:\n",
      "Index(['VVR_1', 'VVR_2', 'AU04_r__variance', 'AU04_r__standard_deviation',\n",
      "       'AU04_r__maximum', 'AU04_r__mean', 'AU04_r__root_mean_square',\n",
      "       'AU09_r__variance', 'AU09_r__standard_deviation', 'AU09_r__mean',\n",
      "       'AU09_r__root_mean_square', 'AU10_r__mean', 'AU14_r__maximum',\n",
      "       'AU23_r__sum_values', 'AU26_r__sum_values',\n",
      "       'AU26_r__standard_deviation', 'AU26_r__mean',\n",
      "       'AU26_r__root_mean_square', 'AU45_r__sum_values',\n",
      "       'AU45_r__root_mean_square'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=20)\n",
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X_train_res, y_train_res, scoring='recall', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('Recall: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "pipeline.fit(X_test, y_test)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X_test.columns[rfe.support_]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.492 (0.363)\n",
      "Selected Features:\n",
      "Index(['VVR_1', 'AU05_r__mean', 'AU17_r__variance', 'AU20_r__sum_values',\n",
      "       'AU26_r__sum_values'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='precision', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('Precision: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.809 (0.085)\n",
      "Selected Features:\n",
      "Index(['VVR_1', 'AU05_r__sum_values', 'AU15_r__standard_deviation',\n",
      "       'AU20_r__sum_values', 'AU26_r__sum_values'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "\n",
    "# Fit the pipeline on the entire dataset\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model including RFE and hyperparameter tuning in Grid Search (not yet with inner and outer split!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.75       0.90909091 0.72727273 0.90909091 1.        ]\n",
      "Mean CV recall:  0.8590909090909091\n",
      "Standard deviation of CV recall:  0.10405021038417814\n",
      "Best parameters found:\n",
      "{'m__n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        25\n",
      "           1       0.62      0.71      0.67         7\n",
      "\n",
      "    accuracy                           0.84        32\n",
      "   macro avg       0.77      0.80      0.78        32\n",
      "weighted avg       0.85      0.84      0.85        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Create the pipeline with RFE and the model\n",
    "rfe_new = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model_new = RandomForestClassifier()\n",
    "pipeline_new = Pipeline(steps=[('s', rfe_new), ('m', model_new)])\n",
    "\n",
    "# Hyperparameter tuning using grid search\n",
    "param_grid = {\n",
    "    'm__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    # 'm__max_depth': [None, 10, 20],  # Maximum depth of the tree\n",
    "    # 'm__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    # 'm__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    # 's__n_features_to_select': [5, 10, 15]  # Number of features to select with RFE\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline_new, param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, X_train_res, y_train_res, cv=cv, scoring='recall')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores: \", cv_scores)\n",
    "print(\"Mean CV recall: \", cv_scores.mean())\n",
    "print(\"Standard deviation of CV recall: \", cv_scores.std())\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Metrics to evaluate\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# # Compute AUC-ROC per class\n",
    "# y_pred_proba = np.array(best_model.predict_proba(X_test)) # Get predicted probabilities\n",
    "\n",
    "# print(y_pred_proba)\n",
    "# print(y_pred_proba.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# auc_per_class = roc_auc_score(y_test.values, y_pred_proba, average=None)\n",
    "\n",
    "# # Print AUC-ROC per class\n",
    "# print(\"AUC-ROC per class:\")\n",
    "# for i, auc in enumerate(auc_per_class):\n",
    "#     print(f\"Class {i}: {auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with inner and outer split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean score using nested cross-validation is: 0.901 Â± 0.046\n",
      "(112, 104)\n",
      "(112,)\n",
      "{'m__class_weight': None, 'm__max_depth': 20, 'm__n_estimators': 100, 's__n_features_to_select': 10}\n",
      "(32,)\n",
      "(32,)\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92        25\n",
      "           1       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.84      0.77      0.79        32\n",
      "weighted avg       0.87      0.88      0.87        32\n",
      "\n",
      "[[24  1]\n",
      " [ 3  4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Declare the inner and outer cross-validation strategies\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "# Create the pipeline with RFE and the model\n",
    "# rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "rfe = RFE(estimator=DecisionTreeClassifier())\n",
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "\n",
    "param_grid = {\n",
    "    'm__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'm__class_weight': [{0: 0.6428571428571429, 1: 2.25}, None],  # Class weights\n",
    "    'm__max_depth': [None, 10, 20],  # Maximum depth of the tree\n",
    "    's__n_features_to_select': [5, 10]  # Number of features to select with RFE\n",
    "}\n",
    "\n",
    "# Inner cross-validation for parameter search\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline, param_grid=param_grid, cv=inner_cv, n_jobs=2\n",
    ")\n",
    "\n",
    "# Outer cross-validation to compute the testing score\n",
    "test_score = cross_val_score(model, X_train_res, y_train_res, cv=outer_cv, n_jobs=2)\n",
    "print(\n",
    "    \"The mean score using nested cross-validation is: \"\n",
    "    f\"{test_score.mean():.3f} Â± {test_score.std():.3f}\"\n",
    ")\n",
    "\n",
    "# Print shape\n",
    "print(X_train_res.shape)\n",
    "print(y_train_res.shape)\n",
    "\n",
    "# Fit model to training data to get best parameters\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Print best parameters\n",
    "print(model.best_params_)\n",
    "\n",
    "# Print the features that were selected with RFE\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = model.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print shape\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# Print classification report \n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "# print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_4/nzq6mygj7j71_l3z_c9kc7wr0000gn/T/ipykernel_4751/2296660790.py:12: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-darkgrid')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "font = 'Times New Roman'\n",
    "size = 18\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Set the style to a modern style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Create a custom diverging color map\n",
    "colors = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=colors, cbar=False,\n",
    "            annot_kws={'fontname': font, 'fontsize': size})  # Set font and size for numbers\n",
    "plt.title('Random Forest', fontname=font, fontsize=size)\n",
    "plt.xlabel('Predicted', fontname=font, fontsize=size)\n",
    "plt.ylabel('Actual', fontname=font, fontsize=size)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For a hyperparameter table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Clone the pipeline to ensure independence\u001b[39;00m\n\u001b[1;32m     41\u001b[0m clf \u001b[38;5;241m=\u001b[39m clone(pipeline)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Collect classification report and accuracy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/pipeline.py:475\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    474\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 475\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1844\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;66;03m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[0;32m-> 1844\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1845\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Capture the thread-local scikit-learn configuration at the time\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Parallel.__call__ is issued since the tasks can be dispatched\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# in a different thread depending on the backend and on the value of\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# pre_dispatch and n_jobs.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m---> 63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:494\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[0;32m--> 494\u001b[0m     \u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:98\u001b[0m, in \u001b[0;36mdelayed\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdelayed\u001b[39m(function):\n\u001b[1;32m     72\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decorator used to capture the arguments of a function.\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m    This alternative to `joblib.delayed` is meant to be used in conjunction\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m        keyword arguments.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;129;43m@functools\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwraps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m---> 98\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mdelayed_function\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_FuncWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m delayed_function\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/functools.py:56\u001b[0m, in \u001b[0;36mupdate_wrapper\u001b[0;34m(wrapper, wrapped, assigned, updated)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m         \u001b[38;5;28;43msetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m updated:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(wrapper, attr)\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mgetattr\u001b[39m(wrapped, attr, {}))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'm__n_estimators': [100, 200, 300],\n",
    "    'm__class_weight': [{0: 0.6428571428571429, 1: 2.25}, None],\n",
    "    'm__max_depth': [None, 10, 20],\n",
    "    's__n_features_to_select': [5, 1, 15]\n",
    "}\n",
    "\n",
    "# Create the pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "\n",
    "# Outer cross-validation\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# Initialize a DataFrame to store the results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each combination of parameters\n",
    "for params in ParameterGrid(param_grid):\n",
    "    # Set the parameters of the pipeline\n",
    "    pipeline.set_params(**params)\n",
    "    \n",
    "    # Collect results for each fold\n",
    "    fold_results = []\n",
    "    for train_idx, test_idx in outer_cv.split(X_train_res, y_train_res):\n",
    "        X_train, X_test = X_train_res.iloc[train_idx], X_train_res.iloc[test_idx]\n",
    "        y_train, y_test = y_train_res[train_idx], y_train_res[test_idx]\n",
    "        \n",
    "        # Clone the pipeline to ensure independence\n",
    "        clf = clone(pipeline)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Collect classification report and accuracy\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Append results to the fold_results\n",
    "        fold_results.append({'params': params, 'accuracy': accuracy, 'report': report})\n",
    "    \n",
    "    # Average the results over the folds\n",
    "    avg_accuracy = sum(result['accuracy'] for result in fold_results) / len(fold_results)\n",
    "    \n",
    "    # Handle averaging of the classification report\n",
    "    avg_report = {}\n",
    "    avg_precision = 0\n",
    "    avg_recall = 0\n",
    "    avg_f1_score = 0\n",
    "    for label in fold_results[0]['report']:\n",
    "        if isinstance(fold_results[0]['report'][label], dict):\n",
    "            avg_report[label] = {\n",
    "                metric: sum(fold_result['report'][label][metric] for fold_result in fold_results) / len(fold_results)\n",
    "                for metric in fold_results[0]['report'][label]\n",
    "            }\n",
    "            if label == 'weighted avg':\n",
    "                avg_precision = avg_report[label]['precision']\n",
    "                avg_recall = avg_report[label]['recall']\n",
    "                avg_f1_score = avg_report[label]['f1-score']\n",
    "        else:\n",
    "            avg_report[label] = sum(fold_result['report'][label] for fold_result in fold_results) / len(fold_results)\n",
    "    \n",
    "    # Add the results to the DataFrame using pd.concat\n",
    "    new_row = pd.DataFrame({\n",
    "        'params': [params], \n",
    "        'accuracy': [avg_accuracy], \n",
    "        'precision': [avg_precision], \n",
    "        'recall': [avg_recall], \n",
    "        'f1-score': [avg_f1_score], \n",
    "        'report': [avg_report]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('/Users/dionnespaltman/Desktop/V4/hyperparameters/grid_search_results.csv', index=False)\n",
    "\n",
    "# Print the results\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
