{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the merged_df dataset. \n",
    "\n",
    "2. Split it into train and test: This step is crucial for evaluating the model's performance. We'll use the 70-30 split, and we'll use X_train_res and y_train_res for training and X_test and y_test for testing.\n",
    "\n",
    "3. Apply SMOTE on the train set: We'll apply SMOTE only to the training set (X_train, y_train) to address class imbalance, resulting in X_train_res and y_train_res.\n",
    "\n",
    "4. Create the pipeline with RFE and the model: We'll create a pipeline that includes Recursive Feature Elimination (RFE) and the chosen model. This pipeline will be trained on the resampled training set (X_train_res, y_train_res).\n",
    "\n",
    "5. Hyperparameter tuning using grid search: We'll perform hyperparameter tuning using grid search within an outer loop of cross-validation. Since grid search involves training multiple models with different hyperparameter combinations, it should be performed on the resampled training set (X_train_res, y_train_res).\n",
    "\n",
    "6. Metrics to evaluate: Finally, we'll evaluate the model's performance using various metrics on the test set (X_test, y_test). Common metrics include accuracy, precision, recall, F1-score, and ROC AUC score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, auc, precision_recall_curve, confusion_matrix\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete_dataset is the dataframe I created with all the extracted features from TS fresh. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sum_12</th>\n",
       "      <th>Sum_4567</th>\n",
       "      <th>VVR_1</th>\n",
       "      <th>VVR_2</th>\n",
       "      <th>Sum_456</th>\n",
       "      <th>VVR_group</th>\n",
       "      <th>Condition</th>\n",
       "      <th>Date</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>AU09_r__sum_values</th>\n",
       "      <th>AU09_r__variance</th>\n",
       "      <th>AU09_r__standard_deviation</th>\n",
       "      <th>AU09_r__maximum</th>\n",
       "      <th>AU09_r__minimum</th>\n",
       "      <th>AU09_r__median</th>\n",
       "      <th>AU09_r__mean</th>\n",
       "      <th>AU09_r__mean_abs_change</th>\n",
       "      <th>AU09_r__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"max\"</th>\n",
       "      <th>AU09_r__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"min\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>24.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-08-01</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1772.86</td>\n",
       "      <td>0.109496</td>\n",
       "      <td>0.330902</td>\n",
       "      <td>4.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.120554</td>\n",
       "      <td>0.019213</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3197.59</td>\n",
       "      <td>0.063365</td>\n",
       "      <td>0.251725</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.117537</td>\n",
       "      <td>0.024182</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>28.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2275.65</td>\n",
       "      <td>0.153114</td>\n",
       "      <td>0.391297</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.138912</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1755.79</td>\n",
       "      <td>0.052783</td>\n",
       "      <td>0.229745</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.099096</td>\n",
       "      <td>0.016996</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20877.08</td>\n",
       "      <td>0.779602</td>\n",
       "      <td>0.882951</td>\n",
       "      <td>3.45</td>\n",
       "      <td>-4.43</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.992115</td>\n",
       "      <td>0.150508</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Sum_12  Sum_4567  VVR_1  VVR_2  Sum_456  VVR_group  Condition  \\\n",
       "0  23    24.0      37.0   13.0   11.0     27.0          0          2   \n",
       "1  24    23.0      37.0   12.0   11.0     28.0          0          2   \n",
       "2  25    28.0      44.0   16.0   12.0     33.0          1          2   \n",
       "3  26    30.0      37.0   15.0   15.0     29.0          0          1   \n",
       "4  27    22.0      39.0   11.0   11.0     31.0          0          2   \n",
       "\n",
       "         Date  Gender  ...  AU09_r__sum_values  AU09_r__variance  \\\n",
       "0  2020-08-01       2  ...             1772.86          0.109496   \n",
       "1  2020-01-22       2  ...             3197.59          0.063365   \n",
       "2  2020-05-02       2  ...             2275.65          0.153114   \n",
       "3  2020-06-02       1  ...             1755.79          0.052783   \n",
       "4  2020-06-02       1  ...            20877.08          0.779602   \n",
       "\n",
       "   AU09_r__standard_deviation  AU09_r__maximum  AU09_r__minimum  \\\n",
       "0                    0.330902             4.98             0.00   \n",
       "1                    0.251725             2.59             0.00   \n",
       "2                    0.391297             4.10             0.00   \n",
       "3                    0.229745             3.25             0.00   \n",
       "4                    0.882951             3.45            -4.43   \n",
       "\n",
       "   AU09_r__median  AU09_r__mean  AU09_r__mean_abs_change  \\\n",
       "0            0.00      0.120554                 0.019213   \n",
       "1            0.00      0.117537                 0.024182   \n",
       "2            0.00      0.138912                 0.024858   \n",
       "3            0.00      0.099096                 0.016996   \n",
       "4            1.05      0.992115                 0.150508   \n",
       "\n",
       "   AU09_r__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"max\"  \\\n",
       "0                                          -0.000032                  \n",
       "1                                          -0.000029                  \n",
       "2                                           0.000048                  \n",
       "3                                          -0.000013                  \n",
       "4                                           0.000089                  \n",
       "\n",
       "   AU09_r__agg_linear_trend__attr_\"slope\"__chunk_len_5__f_agg_\"min\"  \n",
       "0                                          -0.000022                 \n",
       "1                                          -0.000019                 \n",
       "2                                           0.000033                 \n",
       "3                                          -0.000012                 \n",
       "4                                           0.000095                 \n",
       "\n",
       "[5 rows x 360 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "complete_dataset = pd.read_csv('/Users/dionnespaltman/Desktop/V4/complete_dataset.csv', sep=',')\n",
    "complete_dataset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "display(complete_dataset.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to know how many people are in each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in VVR_group = 1: 23\n",
      "Number of instances in VVR_group = 0: 81\n"
     ]
    }
   ],
   "source": [
    "# Count the number of instances of people in VVR_group = 1 and VVR_group = 0\n",
    "count_vvr_group = complete_dataset['VVR_group'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of instances in VVR_group = 1:\", count_vvr_group[1])\n",
    "print(\"Number of instances in VVR_group = 0:\", count_vvr_group[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['ID', 'Sum_12', 'Sum_4567', 'Sum_456', 'VVR_group', 'Condition'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = merged_df.drop(columns_to_drop, axis=1)\n",
    "# y = merged_df['VVR_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the columns I use to predict, so all my features. I need these as a list to establish my featurizer. \n",
    "I have 119 features from TS fresh and then I added the two VVR measurements from stage 1 and 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/dionnespaltman/Desktop/V3/columns_au_12.json', 'r') as f:\n",
    "    columns_au_12 = json.load(f)\n",
    "\n",
    "print(len(columns_au_12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll split the data into a train and test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total, we have 111 participants.\n",
    "\n",
    "I started with a test size of 20%. Then there are only 23 people in the test set (0: 18, 1: 5). \n",
    "Then I made the test size 30%. Then there are 34 people in the test set (0: 26, 1: 8). \n",
    "The best results are however if the test_size is 40%. Then we have 45 participants in the test set (0: 34, 1: 11). \n",
    "\n",
    "Naturally, we stratify on VVR_group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 127)\n",
      "(34, 127)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(merged_df, test_size=0.3, random_state=123, stratify=merged_df['VVR_group'])\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the test set is very small with only 8 people in the high VVR condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 26, 1: 8})\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [ 'ID', 'sum_12', 'sum_4567', 'sum_456', 'VVR_group', 'Condition'] \n",
    "\n",
    "X_test = test.drop(columns_to_drop, axis=1)\n",
    "y_test = test['VVR_group']\n",
    "\n",
    "# Print original class distribution\n",
    "print('Original dataset shape %s' % Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply SMOTE on the train data. The strategy is to make the minority as big as the majority class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 59, 1: 18})\n",
      "Resampled dataset shape Counter({1: 59, 0: 59})\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [ 'ID', 'sum_12', 'sum_4567', 'sum_456', 'VVR_group', 'Condition'] \n",
    "\n",
    "X_train = train.drop(columns_to_drop, axis=1)\n",
    "y_train = train['VVR_group']\n",
    "\n",
    "# Print original class distribution\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "# Apply SMOTE to the training data with sampling strategy set to 'auto' (default)\n",
    "sm = SMOTE(sampling_strategy='not majority', random_state=42, k_neighbors=5)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print resampled class distribution\n",
    "print('Resampled dataset shape %s' % Counter(y_train_res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add class weights to my models, because of my inbalanced data set. \n",
    "https://medium.com/@ravi.abhinav4/improving-class-imbalance-with-class-weights-in-machine-learning-af072fdd4aa4 \n",
    "\n",
    "Results: \n",
    "Class weights: {0: 0.6470588235294118, 1: 2.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.652542372881356, 1: 2.138888888888889}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_class_weights(y):\n",
    "    unique_classes, class_counts = np.unique(y, return_counts=True)\n",
    "    total_samples = len(y)\n",
    "    class_weights = {}\n",
    "\n",
    "    for class_label, class_count in zip(unique_classes, class_counts):\n",
    "        class_weight = total_samples / (2.0 * class_count)\n",
    "        class_weights[class_label] = class_weight\n",
    "\n",
    "    return class_weights\n",
    "\n",
    "# Assuming 'y' contains the class labels (0s and 1s) for the binary classification problem\n",
    "class_weights = calculate_class_weights(y_train)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# this is how you would implement it \n",
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I make the featurizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = ColumnTransformer(transformers=[(\"numeric\", StandardScaler(), columns_au_12)], remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (not complete but a intermediate step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strange enough the recall is much higher (0.27 instead of 0.18) when I don't use class weights. \n",
    "\n",
    "The model you can see here is not using K-fold cross validation. \n",
    "\n",
    "Here I haven't done any Recursive Feature Analysis or cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({1: 51, 0: 51})\n",
      "Accuracy on Validation Data: 0.7777777777777778\n",
      "AUC-PR on Validation Data: 0.5252525252525253\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86        34\n",
      "           1       0.60      0.27      0.38        11\n",
      "\n",
      "    accuracy                           0.78        45\n",
      "   macro avg       0.70      0.61      0.62        45\n",
      "weighted avg       0.75      0.78      0.75        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "\n",
    "# model = make_pipeline(featurizer, RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0, class_weight=class_weights))\n",
    "model = make_pipeline(featurizer, RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0))\n",
    "\n",
    "# here we fit the model on the resampled X train (so the balanced dataset due to SMOTE)\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "print('Original dataset shape %s' % Counter(y_train_res))\n",
    "\n",
    "# Then we predict \n",
    "pred = model.predict(test.drop('VVR_group', axis=1))\n",
    "\n",
    "# The metrics \n",
    "accuracy = accuracy_score(test['VVR_group'].values, pred)\n",
    "report = classification_report(test['VVR_group'].values, pred)\n",
    "cm = confusion_matrix(test['VVR_group'].values, pred)\n",
    "precision, recall, _ = precision_recall_curve(test['VVR_group'].values, pred)\n",
    "auc_pr = auc(recall, precision)\n",
    "\n",
    "# Print results\n",
    "print(f\"Accuracy on Validation Data: {accuracy}\")\n",
    "print(f\"AUC-PR on Validation Data: {auc_pr}\")\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive feature elimination to optimize the scores - not using SMOTE\n",
    "\n",
    "I based my code partially on the following article: \n",
    "https://machinelearningmastery.com/rfe-feature-selection-in-python/\n",
    "\n",
    "Here I did apply cross validation, but not yet with hyperparameter tuning, so it's not the final model yet. \n",
    "\n",
    "For this step we don't use SMOTE because you can't specify what the test and train set is. So here I make a X and y and use this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('/Users/dionnespaltman/Desktop/V3/merged_df.csv', sep=',')\n",
    "\n",
    "merged_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "merged_df.drop('Unnamed: 0.1', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111, 121)\n"
     ]
    }
   ],
   "source": [
    "# columns_to_drop = [ 'ID', 'sum_12', 'sum_4567', 'sum_456', 'VVR_group', 'Condition', 'VVR_1', 'VVR_2'] \n",
    "columns_to_drop = [ 'ID', 'sum_12', 'sum_4567', 'sum_456', 'VVR_group', 'Condition'] \n",
    "\n",
    "X = merged_df.drop(columns_to_drop, axis=1)\n",
    "y = merged_df['VVR_group']\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.500 (0.295)\n"
     ]
    }
   ],
   "source": [
    "# evaluate RFE for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=10)\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='recall', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('Recall: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.436 (0.269)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate RFE for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='precision', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('Precision: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.722 (0.106)\n"
     ]
    }
   ],
   "source": [
    "# evaluate RFE for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create pipeline\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "model = DecisionTreeClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model including RFE and hyperparameter tuning in Grid Search (not yet with inner and outer split!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.75       0.83333333 0.91666667 0.91666667 0.81818182]\n",
      "Mean CV recall:  0.8469696969696969\n",
      "Standard deviation of CV recall:  0.06345573209506641\n",
      "Best parameters found:\n",
      "{'m__n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80        26\n",
      "           1       0.40      0.50      0.44         8\n",
      "\n",
      "    accuracy                           0.71        34\n",
      "   macro avg       0.62      0.63      0.62        34\n",
      "weighted avg       0.73      0.71      0.72        34\n",
      "\n",
      "(34, 2)\n",
      "(34,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create the pipeline with RFE and the model\n",
    "rfe_new = RFE(estimator=RandomForestClassifier(), n_features_to_select=10)\n",
    "model_new = RandomForestClassifier()\n",
    "pipeline_new = Pipeline(steps=[('s', rfe_new), ('m', model_new)])\n",
    "\n",
    "# Hyperparameter tuning using grid search\n",
    "param_grid = {\n",
    "    'm__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    # 'm__max_depth': [None, 10, 20],  # Maximum depth of the tree\n",
    "    # 'm__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    # 'm__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    # 's__n_features_to_select': [5, 10, 15]  # Number of features to select with RFE\n",
    "}\n",
    "grid_search = GridSearchCV(pipeline_new, param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(grid_search.best_estimator_, X_train_res, y_train_res, cv=cv, scoring='recall')\n",
    "\n",
    "# Print cross-validation scores\n",
    "print(\"Cross-validation scores: \", cv_scores)\n",
    "print(\"Mean CV recall: \", cv_scores.mean())\n",
    "print(\"Standard deviation of CV recall: \", cv_scores.std())\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Metrics to evaluate\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Compute AUC-ROC per class\n",
    "y_pred_proba = best_model.predict_proba(X_test)  # Get predicted probabilities\n",
    "\n",
    "print(y_pred_proba.shape)\n",
    "print(y_test.shape)\n",
    "# auc_per_class = roc_auc_score(y_test, y_pred_proba, average=None)\n",
    "\n",
    "# # Print AUC-ROC per class\n",
    "# print(\"AUC-ROC per class:\")\n",
    "# for i, auc in enumerate(auc_per_class):\n",
    "#     print(f\"Class {i}: {auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with inner and outer split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean score using nested cross-validation is: 0.822 ± 0.019\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 38\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe mean score using nested cross-validation is: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_score\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_score\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# # Print best parameters\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# print(\"Best parameters found:\")\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# print(model.best_estimator_.named_steps['m'].get_params())  # Adjust 'm' if necessary\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# # print(model.best_params_)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Evaluate on the test set\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_estimator_\u001b[49m\n\u001b[1;32m     39\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mClassification Report on Test Set:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Declare the inner and outer cross-validation strategies\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the pipeline with RFE and the model\n",
    "rfe_new = RFE(estimator=RandomForestClassifier(), n_features_to_select=10)\n",
    "model_new = RandomForestClassifier()\n",
    "pipeline_new = Pipeline(steps=[('s', rfe_new), ('m', model_new)])\n",
    "\n",
    "param_grid = {\n",
    "    'm__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    # 'm__max_depth': [None, 10, 20],  # Maximum depth of the tree\n",
    "    # 'm__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    # 'm__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    # 's__n_features_to_select': [10, 20, 30, 40]  # Number of features to select with RFE\n",
    "}\n",
    "\n",
    "# Inner cross-validation for parameter search\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline_new, param_grid=param_grid, cv=inner_cv, n_jobs=2\n",
    ")\n",
    "\n",
    "# Outer cross-validation to compute the testing score\n",
    "test_score = cross_val_score(model, X_train_res, y_train_res, cv=outer_cv, n_jobs=2)\n",
    "print(\n",
    "    \"The mean score using nested cross-validation is: \"\n",
    "    f\"{test_score.mean():.3f} ± {test_score.std():.3f}\"\n",
    ")\n",
    "\n",
    "# # Print best parameters\n",
    "# print(\"Best parameters found:\")\n",
    "# print(model.best_estimator_.named_steps['m'].get_params())  # Adjust 'm' if necessary\n",
    "# # print(model.best_params_)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = model.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 121)\n",
      "(102, 121)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train_res.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
