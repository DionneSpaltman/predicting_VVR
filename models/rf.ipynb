{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, auc, precision_recall_curve, confusion_matrix\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merged df is the dataframe I created with all the extracted features from TS fresh. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sum_12</th>\n",
       "      <th>sum_4567</th>\n",
       "      <th>sum_456</th>\n",
       "      <th>VVR_group</th>\n",
       "      <th>Condition</th>\n",
       "      <th>VVR_1</th>\n",
       "      <th>VVR_2</th>\n",
       "      <th>AU01_r__sum_values</th>\n",
       "      <th>AU01_r__variance</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_r__minimum</th>\n",
       "      <th>AU26_r__mean</th>\n",
       "      <th>AU26_r__mean_abs_change</th>\n",
       "      <th>AU45_r__sum_values</th>\n",
       "      <th>AU45_r__variance</th>\n",
       "      <th>AU45_r__standard_deviation</th>\n",
       "      <th>AU45_r__maximum</th>\n",
       "      <th>AU45_r__minimum</th>\n",
       "      <th>AU45_r__mean</th>\n",
       "      <th>AU45_r__mean_abs_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>24.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4982.48</td>\n",
       "      <td>0.425041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.633284</td>\n",
       "      <td>0.076328</td>\n",
       "      <td>9231.74</td>\n",
       "      <td>0.825039</td>\n",
       "      <td>0.908316</td>\n",
       "      <td>4.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.627753</td>\n",
       "      <td>0.133624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9390.23</td>\n",
       "      <td>0.448366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.484701</td>\n",
       "      <td>0.125851</td>\n",
       "      <td>11887.00</td>\n",
       "      <td>0.634554</td>\n",
       "      <td>0.796589</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.436942</td>\n",
       "      <td>0.098134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>28.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6954.35</td>\n",
       "      <td>0.599805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.862301</td>\n",
       "      <td>0.101969</td>\n",
       "      <td>9020.78</td>\n",
       "      <td>0.750701</td>\n",
       "      <td>0.866430</td>\n",
       "      <td>4.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.550652</td>\n",
       "      <td>0.085720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9707.43</td>\n",
       "      <td>0.873280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.552359</td>\n",
       "      <td>0.069582</td>\n",
       "      <td>6585.31</td>\n",
       "      <td>0.609348</td>\n",
       "      <td>0.780607</td>\n",
       "      <td>4.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.371673</td>\n",
       "      <td>0.056287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>22.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>21049.90</td>\n",
       "      <td>1.475421</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.92</td>\n",
       "      <td>0.142027</td>\n",
       "      <td>0.386527</td>\n",
       "      <td>23027.73</td>\n",
       "      <td>1.160635</td>\n",
       "      <td>1.077328</td>\n",
       "      <td>5.04</td>\n",
       "      <td>-4.29</td>\n",
       "      <td>1.094318</td>\n",
       "      <td>0.231853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  sum_12  sum_4567  sum_456  VVR_group  Condition  VVR_1  VVR_2  \\\n",
       "0  23    24.0      37.0     27.0          0          2   13.0   11.0   \n",
       "1  24    23.0      37.0     28.0          0          2   12.0   11.0   \n",
       "2  25    28.0      44.0     33.0          1          2   16.0   12.0   \n",
       "3  26    30.0      37.0     29.0          0          1   15.0   15.0   \n",
       "4  27    22.0      39.0     31.0          1          2   11.0   11.0   \n",
       "\n",
       "   AU01_r__sum_values  AU01_r__variance  ...  AU26_r__minimum  AU26_r__mean  \\\n",
       "0             4982.48          0.425041  ...             0.00      0.633284   \n",
       "1             9390.23          0.448366  ...             0.00      1.484701   \n",
       "2             6954.35          0.599805  ...             0.00      0.862301   \n",
       "3             9707.43          0.873280  ...             0.00      0.552359   \n",
       "4            21049.90          1.475421  ...            -3.92      0.142027   \n",
       "\n",
       "   AU26_r__mean_abs_change  AU45_r__sum_values  AU45_r__variance  \\\n",
       "0                 0.076328             9231.74          0.825039   \n",
       "1                 0.125851            11887.00          0.634554   \n",
       "2                 0.101969             9020.78          0.750701   \n",
       "3                 0.069582             6585.31          0.609348   \n",
       "4                 0.386527            23027.73          1.160635   \n",
       "\n",
       "   AU45_r__standard_deviation  AU45_r__maximum  AU45_r__minimum  AU45_r__mean  \\\n",
       "0                    0.908316             4.91             0.00      0.627753   \n",
       "1                    0.796589             5.00             0.00      0.436942   \n",
       "2                    0.866430             4.04             0.00      0.550652   \n",
       "3                    0.780607             4.90             0.00      0.371673   \n",
       "4                    1.077328             5.04            -4.29      1.094318   \n",
       "\n",
       "   AU45_r__mean_abs_change  \n",
       "0                 0.133624  \n",
       "1                 0.098134  \n",
       "2                 0.085720  \n",
       "3                 0.056287  \n",
       "4                 0.231853  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_df = pd.read_csv('/Users/dionnespaltman/Desktop/V3/merged_df.csv', sep=',')\n",
    "\n",
    "merged_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "merged_df.drop('Unnamed: 0.1', axis=1, inplace=True)\n",
    "\n",
    "display(merged_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to know how many people are in each group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances in VVR_group = 1: 26\n",
      "Number of instances in VVR_group = 0: 85\n"
     ]
    }
   ],
   "source": [
    "# Count the number of instances of people in VVR_group = 1 and VVR_group = 0\n",
    "count_vvr_group = merged_df['VVR_group'].value_counts()\n",
    "\n",
    "# Print the counts\n",
    "print(\"Number of instances in VVR_group = 1:\", count_vvr_group[1])\n",
    "print(\"Number of instances in VVR_group = 0:\", count_vvr_group[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the columns I use to predict, so all my features. I need these as a list to establish my featurizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/dionnespaltman/Desktop/V3/columns_au_12.json', 'r') as f:\n",
    "    columns_au_12 = json.load(f)\n",
    "\n",
    "print(len(columns_au_12))\n",
    "# print(columns_au_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [ 'ID', 'sum_12', 'sum_4567', 'sum_456', 'VVR_group', 'Condition'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll split the data into a train and test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train set has 88 participants, the test set has 23 participants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77, 127)\n",
      "(34, 127)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(merged_df, test_size=0.3, random_state=123, stratify=merged_df['VVR_group'])\n",
    "# train, val = train_test_split(train, stratify=train['VVR_group'], random_state=123)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunaly, the test set is very small with only 4 people in the high VVR condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 26, 1: 8})\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [ 'ID', 'sum_12', 'sum_4567', 'sum_456', 'VVR_group', 'Condition'] \n",
    "\n",
    "X_test = test.drop(columns_to_drop, axis=1)\n",
    "y_test = test['VVR_group']\n",
    "\n",
    "# Print original class distribution\n",
    "print('Original dataset shape %s' % Counter(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 59, 1: 18})\n",
      "Resampled dataset shape Counter({1: 59, 0: 59})\n",
      "New merged dataset shape: (118, 122)\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [ 'ID', 'sum_12', 'sum_4567', 'sum_456', 'VVR_group', 'Condition'] \n",
    "\n",
    "X_train = train.drop(columns_to_drop, axis=1)\n",
    "y_train = train['VVR_group']\n",
    "\n",
    "# Print original class distribution\n",
    "print('Original dataset shape %s' % Counter(y_train))\n",
    "\n",
    "# Apply SMOTE to the training data with sampling strategy set to 'auto' (default)\n",
    "sm = SMOTE(sampling_strategy='not majority', random_state=42, k_neighbors=5)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print resampled class distribution\n",
    "print('Resampled dataset shape %s' % Counter(y_resampled))\n",
    "\n",
    "# Merge resampled features and target variable into a new DataFrame\n",
    "new_merged_df = pd.merge(X_resampled, y_resampled, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "# Check the shape of the new merged DataFrame\n",
    "print('New merged dataset shape:', new_merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = ColumnTransformer(transformers=[(\"numeric\", StandardScaler(), columns_au_12)], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dummy = make_pipeline(featurizer, DummyClassifier(strategy='most_frequent'))\n",
    "rf = make_pipeline(featurizer, RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=0))\n",
    "svm = make_pipeline(featurizer, SVC())\n",
    "multiclass_svm = make_pipeline(featurizer, SVC(decision_function_shape='ovr'))\n",
    "xgb = make_pipeline(featurizer, XGBClassifier())\n",
    "mlp = make_pipeline(featurizer, MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000))\n",
    "decision_tree = make_pipeline(featurizer, DecisionTreeClassifier())\n",
    "\n",
    "models = {\n",
    "    \"Dummy\": dummy,\n",
    "    \"RandomForest\": rf,\n",
    "    \"SVM\": svm,\n",
    "    \"Multiclass SVM\": multiclass_svm,\n",
    "    \"XGBoost\": xgb,\n",
    "    \"MLP\": mlp,\n",
    "    \"DecisionTree\": decision_tree\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['VVR_group'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m precision, recall, _ \u001b[38;5;241m=\u001b[39m precision_recall_curve(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVVR_group\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, pred)\n\u001b[1;32m     14\u001b[0m auc_pr \u001b[38;5;241m=\u001b[39m auc(recall, precision)\n\u001b[0;32m---> 15\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVVR_group\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues, model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVVR_group\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     17\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m AUC-PR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc_pr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Including AUC-PR in logging\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:4957\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4811\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4818\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4819\u001b[0m ):\n\u001b[1;32m   4820\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4821\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4822\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4955\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4956\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4964\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6661\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6662\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['VVR_group'] not found in axis\""
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix as cm\n",
    "\n",
    "logging.info(\"Fitting models\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(train.drop('VVR_group', axis=1), train['VVR_group'].values)\n",
    "    logging.info(f\"Evaluating {name} on validation data\")\n",
    "    pred = model.predict(test.drop('VVR_group', axis=1))\n",
    "    accuracy = accuracy_score(test['VVR_group'].values, pred)\n",
    "    report = classification_report(test['VVR_group'].values, pred)\n",
    "    \n",
    "    # Calculating Precision-Recall curve and its AUC\n",
    "    precision, recall, _ = precision_recall_curve(test['VVR_group'].values, pred)\n",
    "    auc_pr = auc(recall, precision)\n",
    "\n",
    "    logging.info(f\"{name} Accuracy: {accuracy}\")\n",
    "    logging.info(f\"{name} AUC-PR: {auc_pr}\")  # Including AUC-PR in logging\n",
    "    logging.info(f\"{name} Classification Report:\")\n",
    "    logging.info(report)\n",
    "    logging.info(f\"{name} Confusion Matrix:\")\n",
    "    logging.info(cm)\n",
    "\n",
    "best_model_name = max(models, key=lambda x: accuracy_score(test['VVR_group'].values, models[x].predict(test.drop('VVR_group', axis=1))))\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "logging.info(f\"Predicting on test using best model: {best_model_name}\")\n",
    "\n",
    "pred = best_model.predict(test.drop('VVR_group', axis=1))\n",
    "\n",
    "accuracy = accuracy_score(test['VVR_group'].values, pred)\n",
    "report = classification_report(test['VVR_group'].values, pred)\n",
    "cm = confusion_matrix(test['VVR_group'].values, pred)\n",
    "\n",
    "logging.info(f\"{best_model_name} Accuracy on Test Data: {accuracy}\")\n",
    "logging.info(f\"{best_model_name} Classification Report on Test Data:\")\n",
    "logging.info(report)\n",
    "logging.info(f\"{best_model_name} Confusion Matrix:\")\n",
    "logging.info(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance\n",
    "    \"\"\"\n",
    "    model.fit(X, y)\n",
    "    y_probs = model.predict_proba(X)[:, 1]\n",
    "    precision = precision_score(y, model.predict(X))\n",
    "    recall = recall_score(y, model.predict(X))\n",
    "    f1 = f1_score(y, model.predict(X))\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y, y_probs)\n",
    "    auc_pr = auc(recall_curve, precision_curve)\n",
    "    cm = confusion_matrix(y, model.predict(X))\n",
    "    \n",
    "    logging.info(f\"Precision: {precision}\")\n",
    "    logging.info(f\"Recall: {recall}\")\n",
    "    logging.info(f\"F1-score: {f1}\")\n",
    "    logging.info(f\"AUC-PR score: {auc_pr}\")\n",
    "    logging.info(f\"Confusion Matrix:\")\n",
    "    logging.info(cm)\n",
    "\n",
    "evaluate_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
