{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, auc, precision_recall_curve, confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_res:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU01_r__sum_values</th>\n",
       "      <th>AU01_r__variance</th>\n",
       "      <th>AU01_r__standard_deviation</th>\n",
       "      <th>AU01_r__maximum</th>\n",
       "      <th>AU01_r__mean</th>\n",
       "      <th>AU01_r__root_mean_square</th>\n",
       "      <th>AU02_r__sum_values</th>\n",
       "      <th>AU02_r__variance</th>\n",
       "      <th>AU02_r__standard_deviation</th>\n",
       "      <th>AU02_r__maximum</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_r__standard_deviation</th>\n",
       "      <th>AU26_r__maximum</th>\n",
       "      <th>AU26_r__mean</th>\n",
       "      <th>AU26_r__root_mean_square</th>\n",
       "      <th>AU45_r__sum_values</th>\n",
       "      <th>AU45_r__variance</th>\n",
       "      <th>AU45_r__standard_deviation</th>\n",
       "      <th>AU45_r__maximum</th>\n",
       "      <th>AU45_r__mean</th>\n",
       "      <th>AU45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.114682</td>\n",
       "      <td>-0.412734</td>\n",
       "      <td>-0.175865</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>-0.687555</td>\n",
       "      <td>-0.400360</td>\n",
       "      <td>0.970556</td>\n",
       "      <td>0.364929</td>\n",
       "      <td>0.619745</td>\n",
       "      <td>0.879270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.588472</td>\n",
       "      <td>0.201653</td>\n",
       "      <td>-1.080948</td>\n",
       "      <td>-1.005558</td>\n",
       "      <td>-1.057202</td>\n",
       "      <td>-1.532650</td>\n",
       "      <td>-1.499128</td>\n",
       "      <td>-1.273469</td>\n",
       "      <td>-2.129886</td>\n",
       "      <td>-2.037173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.038570</td>\n",
       "      <td>-0.768864</td>\n",
       "      <td>-0.561401</td>\n",
       "      <td>0.504332</td>\n",
       "      <td>-0.809168</td>\n",
       "      <td>-0.758472</td>\n",
       "      <td>0.333551</td>\n",
       "      <td>-0.368145</td>\n",
       "      <td>-0.254851</td>\n",
       "      <td>0.396542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289276</td>\n",
       "      <td>0.440930</td>\n",
       "      <td>0.189637</td>\n",
       "      <td>0.225341</td>\n",
       "      <td>1.063062</td>\n",
       "      <td>0.406128</td>\n",
       "      <td>0.477464</td>\n",
       "      <td>0.619122</td>\n",
       "      <td>-0.068091</td>\n",
       "      <td>0.354797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.436004</td>\n",
       "      <td>0.206480</td>\n",
       "      <td>0.369342</td>\n",
       "      <td>0.158133</td>\n",
       "      <td>-0.021607</td>\n",
       "      <td>0.244861</td>\n",
       "      <td>-0.836108</td>\n",
       "      <td>-0.490845</td>\n",
       "      <td>-0.445781</td>\n",
       "      <td>-0.359971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522235</td>\n",
       "      <td>0.440930</td>\n",
       "      <td>0.181549</td>\n",
       "      <td>0.373204</td>\n",
       "      <td>-0.399350</td>\n",
       "      <td>0.048667</td>\n",
       "      <td>0.213801</td>\n",
       "      <td>-0.150745</td>\n",
       "      <td>0.132589</td>\n",
       "      <td>0.169110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558569</td>\n",
       "      <td>0.560424</td>\n",
       "      <td>0.637285</td>\n",
       "      <td>0.504332</td>\n",
       "      <td>0.287352</td>\n",
       "      <td>0.558101</td>\n",
       "      <td>0.411212</td>\n",
       "      <td>0.165073</td>\n",
       "      <td>0.411670</td>\n",
       "      <td>0.893680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045264</td>\n",
       "      <td>0.440930</td>\n",
       "      <td>-0.462771</td>\n",
       "      <td>-0.331676</td>\n",
       "      <td>-0.090762</td>\n",
       "      <td>-0.747721</td>\n",
       "      <td>-0.481159</td>\n",
       "      <td>0.330422</td>\n",
       "      <td>-0.600511</td>\n",
       "      <td>-0.671622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039454</td>\n",
       "      <td>0.762845</td>\n",
       "      <td>0.780378</td>\n",
       "      <td>0.364379</td>\n",
       "      <td>0.528676</td>\n",
       "      <td>0.748981</td>\n",
       "      <td>-0.131359</td>\n",
       "      <td>0.091414</td>\n",
       "      <td>0.330497</td>\n",
       "      <td>-0.057366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.535630</td>\n",
       "      <td>0.440930</td>\n",
       "      <td>-0.856850</td>\n",
       "      <td>-0.858808</td>\n",
       "      <td>0.063929</td>\n",
       "      <td>0.829485</td>\n",
       "      <td>0.764250</td>\n",
       "      <td>0.619122</td>\n",
       "      <td>0.779664</td>\n",
       "      <td>0.855063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AU01_r__sum_values  AU01_r__variance  AU01_r__standard_deviation  \\\n",
       "0           -0.114682         -0.412734                   -0.175865   \n",
       "1           -0.038570         -0.768864                   -0.561401   \n",
       "2           -0.436004          0.206480                    0.369342   \n",
       "3            0.558569          0.560424                    0.637285   \n",
       "4            0.039454          0.762845                    0.780378   \n",
       "\n",
       "   AU01_r__maximum  AU01_r__mean  AU01_r__root_mean_square  \\\n",
       "0         0.415941     -0.687555                 -0.400360   \n",
       "1         0.504332     -0.809168                 -0.758472   \n",
       "2         0.158133     -0.021607                  0.244861   \n",
       "3         0.504332      0.287352                  0.558101   \n",
       "4         0.364379      0.528676                  0.748981   \n",
       "\n",
       "   AU02_r__sum_values  AU02_r__variance  AU02_r__standard_deviation  \\\n",
       "0            0.970556          0.364929                    0.619745   \n",
       "1            0.333551         -0.368145                   -0.254851   \n",
       "2           -0.836108         -0.490845                   -0.445781   \n",
       "3            0.411212          0.165073                    0.411670   \n",
       "4           -0.131359          0.091414                    0.330497   \n",
       "\n",
       "   AU02_r__maximum  ...  AU26_r__standard_deviation  AU26_r__maximum  \\\n",
       "0         0.879270  ...                   -0.588472         0.201653   \n",
       "1         0.396542  ...                    0.289276         0.440930   \n",
       "2        -0.359971  ...                    0.522235         0.440930   \n",
       "3         0.893680  ...                   -0.045264         0.440930   \n",
       "4        -0.057366  ...                   -0.535630         0.440930   \n",
       "\n",
       "   AU26_r__mean  AU26_r__root_mean_square  AU45_r__sum_values  \\\n",
       "0     -1.080948                 -1.005558           -1.057202   \n",
       "1      0.189637                  0.225341            1.063062   \n",
       "2      0.181549                  0.373204           -0.399350   \n",
       "3     -0.462771                 -0.331676           -0.090762   \n",
       "4     -0.856850                 -0.858808            0.063929   \n",
       "\n",
       "   AU45_r__variance  AU45_r__standard_deviation  AU45_r__maximum  \\\n",
       "0         -1.532650                   -1.499128        -1.273469   \n",
       "1          0.406128                    0.477464         0.619122   \n",
       "2          0.048667                    0.213801        -0.150745   \n",
       "3         -0.747721                   -0.481159         0.330422   \n",
       "4          0.829485                    0.764250         0.619122   \n",
       "\n",
       "   AU45_r__mean  AU45_r__root_mean_square  \n",
       "0     -2.129886                 -2.037173  \n",
       "1     -0.068091                  0.354797  \n",
       "2      0.132589                  0.169110  \n",
       "3     -0.600511                 -0.671622  \n",
       "4      0.779664                  0.855063  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train_res:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VVR_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VVR_group\n",
       "0          1\n",
       "1          1\n",
       "2          1\n",
       "3          0\n",
       "4          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AU01_r__sum_values</th>\n",
       "      <th>AU01_r__variance</th>\n",
       "      <th>AU01_r__standard_deviation</th>\n",
       "      <th>AU01_r__maximum</th>\n",
       "      <th>AU01_r__mean</th>\n",
       "      <th>AU01_r__root_mean_square</th>\n",
       "      <th>AU02_r__sum_values</th>\n",
       "      <th>AU02_r__variance</th>\n",
       "      <th>AU02_r__standard_deviation</th>\n",
       "      <th>AU02_r__maximum</th>\n",
       "      <th>...</th>\n",
       "      <th>AU26_r__standard_deviation</th>\n",
       "      <th>AU26_r__maximum</th>\n",
       "      <th>AU26_r__mean</th>\n",
       "      <th>AU26_r__root_mean_square</th>\n",
       "      <th>AU45_r__sum_values</th>\n",
       "      <th>AU45_r__variance</th>\n",
       "      <th>AU45_r__standard_deviation</th>\n",
       "      <th>AU45_r__maximum</th>\n",
       "      <th>AU45_r__mean</th>\n",
       "      <th>AU45_r__root_mean_square</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.954248</td>\n",
       "      <td>-0.951158</td>\n",
       "      <td>-0.794258</td>\n",
       "      <td>-2.000083</td>\n",
       "      <td>0.255940</td>\n",
       "      <td>-0.532746</td>\n",
       "      <td>-1.756362</td>\n",
       "      <td>-0.587427</td>\n",
       "      <td>-0.613203</td>\n",
       "      <td>-1.822564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166497</td>\n",
       "      <td>-0.729816</td>\n",
       "      <td>2.825468</td>\n",
       "      <td>1.673580</td>\n",
       "      <td>-2.233545</td>\n",
       "      <td>0.289550</td>\n",
       "      <td>0.393906</td>\n",
       "      <td>-0.511621</td>\n",
       "      <td>1.873165</td>\n",
       "      <td>0.899641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.531321</td>\n",
       "      <td>-0.178666</td>\n",
       "      <td>0.044588</td>\n",
       "      <td>0.504332</td>\n",
       "      <td>-0.398439</td>\n",
       "      <td>-0.134585</td>\n",
       "      <td>-0.306588</td>\n",
       "      <td>-0.141707</td>\n",
       "      <td>0.053531</td>\n",
       "      <td>-0.172644</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.363370</td>\n",
       "      <td>-0.080351</td>\n",
       "      <td>-0.509222</td>\n",
       "      <td>-0.565219</td>\n",
       "      <td>-0.579429</td>\n",
       "      <td>-0.022861</td>\n",
       "      <td>0.158174</td>\n",
       "      <td>0.466753</td>\n",
       "      <td>-0.568289</td>\n",
       "      <td>-0.075143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.293895</td>\n",
       "      <td>0.814623</td>\n",
       "      <td>0.815957</td>\n",
       "      <td>0.504332</td>\n",
       "      <td>0.187131</td>\n",
       "      <td>0.677928</td>\n",
       "      <td>0.120579</td>\n",
       "      <td>1.064580</td>\n",
       "      <td>1.247824</td>\n",
       "      <td>0.900885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567536</td>\n",
       "      <td>0.440930</td>\n",
       "      <td>0.271424</td>\n",
       "      <td>0.449194</td>\n",
       "      <td>-0.116745</td>\n",
       "      <td>0.791976</td>\n",
       "      <td>0.739793</td>\n",
       "      <td>0.129936</td>\n",
       "      <td>0.675229</td>\n",
       "      <td>0.802541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.462186</td>\n",
       "      <td>-0.190678</td>\n",
       "      <td>0.033761</td>\n",
       "      <td>0.504332</td>\n",
       "      <td>-0.500519</td>\n",
       "      <td>-0.171970</td>\n",
       "      <td>0.077514</td>\n",
       "      <td>0.198167</td>\n",
       "      <td>0.447299</td>\n",
       "      <td>0.648713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.187859</td>\n",
       "      <td>0.346928</td>\n",
       "      <td>-0.008672</td>\n",
       "      <td>0.055083</td>\n",
       "      <td>-0.336010</td>\n",
       "      <td>-0.518784</td>\n",
       "      <td>-0.261437</td>\n",
       "      <td>-0.190843</td>\n",
       "      <td>-0.460154</td>\n",
       "      <td>-0.433136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.797969</td>\n",
       "      <td>2.225527</td>\n",
       "      <td>1.667268</td>\n",
       "      <td>0.504332</td>\n",
       "      <td>1.289613</td>\n",
       "      <td>1.707848</td>\n",
       "      <td>1.420513</td>\n",
       "      <td>0.971025</td>\n",
       "      <td>1.170829</td>\n",
       "      <td>0.893680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>0.440930</td>\n",
       "      <td>-0.477280</td>\n",
       "      <td>-0.360369</td>\n",
       "      <td>0.855433</td>\n",
       "      <td>0.216467</td>\n",
       "      <td>0.340371</td>\n",
       "      <td>0.202111</td>\n",
       "      <td>0.358639</td>\n",
       "      <td>0.349728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AU01_r__sum_values  AU01_r__variance  AU01_r__standard_deviation  \\\n",
       "0           -1.954248         -0.951158                   -0.794258   \n",
       "1           -0.531321         -0.178666                    0.044588   \n",
       "2           -0.293895          0.814623                    0.815957   \n",
       "3           -0.462186         -0.190678                    0.033761   \n",
       "4            1.797969          2.225527                    1.667268   \n",
       "\n",
       "   AU01_r__maximum  AU01_r__mean  AU01_r__root_mean_square  \\\n",
       "0        -2.000083      0.255940                 -0.532746   \n",
       "1         0.504332     -0.398439                 -0.134585   \n",
       "2         0.504332      0.187131                  0.677928   \n",
       "3         0.504332     -0.500519                 -0.171970   \n",
       "4         0.504332      1.289613                  1.707848   \n",
       "\n",
       "   AU02_r__sum_values  AU02_r__variance  AU02_r__standard_deviation  \\\n",
       "0           -1.756362         -0.587427                   -0.613203   \n",
       "1           -0.306588         -0.141707                    0.053531   \n",
       "2            0.120579          1.064580                    1.247824   \n",
       "3            0.077514          0.198167                    0.447299   \n",
       "4            1.420513          0.971025                    1.170829   \n",
       "\n",
       "   AU02_r__maximum  ...  AU26_r__standard_deviation  AU26_r__maximum  \\\n",
       "0        -1.822564  ...                   -0.166497        -0.729816   \n",
       "1        -0.172644  ...                   -0.363370        -0.080351   \n",
       "2         0.900885  ...                    0.567536         0.440930   \n",
       "3         0.648713  ...                    0.187859         0.346928   \n",
       "4         0.893680  ...                   -0.077072         0.440930   \n",
       "\n",
       "   AU26_r__mean  AU26_r__root_mean_square  AU45_r__sum_values  \\\n",
       "0      2.825468                  1.673580           -2.233545   \n",
       "1     -0.509222                 -0.565219           -0.579429   \n",
       "2      0.271424                  0.449194           -0.116745   \n",
       "3     -0.008672                  0.055083           -0.336010   \n",
       "4     -0.477280                 -0.360369            0.855433   \n",
       "\n",
       "   AU45_r__variance  AU45_r__standard_deviation  AU45_r__maximum  \\\n",
       "0          0.289550                    0.393906        -0.511621   \n",
       "1         -0.022861                    0.158174         0.466753   \n",
       "2          0.791976                    0.739793         0.129936   \n",
       "3         -0.518784                   -0.261437        -0.190843   \n",
       "4          0.216467                    0.340371         0.202111   \n",
       "\n",
       "   AU45_r__mean  AU45_r__root_mean_square  \n",
       "0      1.873165                  0.899641  \n",
       "1     -0.568289                 -0.075143  \n",
       "2      0.675229                  0.802541  \n",
       "3     -0.460154                 -0.433136  \n",
       "4      0.358639                  0.349728  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VVR_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VVR_group\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data into pandas dataframes\n",
    "X_train_res = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/X_train_resampled.csv')\n",
    "y_train_res = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/y_train_resampled.csv')\n",
    "X_test = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/X_test.csv')\n",
    "y_test = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/y_test.csv')\n",
    "\n",
    "X_train_res = X_train_res.drop(columns='Unnamed: 0', axis=1)\n",
    "y_train_res = y_train_res.drop(columns='Unnamed: 0', axis=1)\n",
    "X_test = X_test.drop(columns='Unnamed: 0', axis=1)\n",
    "y_test = y_test.drop(columns='Unnamed: 0', axis=1)\n",
    "\n",
    "columns_VVR = ['Sum_1', 'Sum_2']\n",
    "\n",
    "X_train_res  = X_train_res.drop(columns=columns_VVR, axis=1)\n",
    "X_test  = X_test.drop(columns=columns_VVR, axis=1)\n",
    "\n",
    "# Display the first few rows of each dataframe to verify the loading\n",
    "print(\"X_train_res:\")\n",
    "display(X_train_res.head())\n",
    "\n",
    "print(\"\\ny_train_res:\")\n",
    "display(y_train_res.head())\n",
    "\n",
    "print(\"\\nX_test:\")\n",
    "display(X_test.head())\n",
    "\n",
    "print(\"\\ny_test:\")\n",
    "# print(y_test)\n",
    "display(y_test.head())\n",
    "\n",
    "# Convert the DataFrame to a 1-dimensional NumPy array\n",
    "y_train_res = y_train_res.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with inner and outer split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 38\u001b[0m\n\u001b[1;32m     33\u001b[0m model \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     34\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39minner_cv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Outer cross-validation to compute the testing score\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m test_score \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_res\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mouter_cv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe mean score using nested cross-validation is: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_score\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Â± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_score\u001b[38;5;241m.\u001b[39mstd()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m )\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Print shape\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # early-stop warnings\n",
    "\n",
    "# Declare the inner and outer cross-validation strategies\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the pipeline with RFE and the model\n",
    "# rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "rfe = RFE(estimator=DecisionTreeClassifier())\n",
    "\n",
    "model = MLPClassifier(max_iter=1000, solver='adam', learning_rate_init=0.001)\n",
    "pipeline = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "\n",
    "param_grid = {\n",
    "    'm__hidden_layer_sizes': [(100,), (50, 50), (50, 100, 50)],  # Size of hidden layers\n",
    "    'm__activation': ['relu', 'tanh', 'logistic'],  # Activation function\n",
    "    # 'm__solver': ['adam', 'sgd'],  # Optimization algorithm\n",
    "    'm__alpha': [0.0001, 0.001, 0.01],  # L2 penalty (regularization term) parameter\n",
    "    'm__learning_rate': ['constant', 'adaptive'],  # Learning rate schedule for weight updates\n",
    "    's__n_features_to_select': [5, 10, 20, 40, 60, 80]  # Number of features to select with RFE\n",
    "}\n",
    "\n",
    "# Inner cross-validation for parameter search\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline, param_grid=param_grid, cv=inner_cv, n_jobs=2\n",
    ")\n",
    "\n",
    "# Outer cross-validation to compute the testing score\n",
    "test_score = cross_val_score(model, X_train_res, y_train_res, cv=outer_cv, n_jobs=2)\n",
    "print(\n",
    "    \"The mean score using nested cross-validation is: \"\n",
    "    f\"{test_score.mean():.3f} Â± {test_score.std():.3f}\"\n",
    ")\n",
    "\n",
    "# Print shape\n",
    "print(X_train_res.shape)\n",
    "print(y_train_res.shape)\n",
    "\n",
    "# Fit model to training data to get best parameters\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Print best parameters\n",
    "print(model.best_params_)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = model.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print shape\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# Print classification report \n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate and print the AUC-PR\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]  # Get the probabilities for the positive class\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "auc_pr = auc(recall, precision)\n",
    "print(f\"AUC-PR: {auc_pr:.3f}\")\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "# print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # early-stop warnings\n",
    "\n",
    "# Declare the inner and outer cross-validation strategies\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the pipeline with RFE and the model\n",
    "# rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)\n",
    "rfe = RFE(estimator=DecisionTreeClassifier())\n",
    "\n",
    "model = MLPClassifier(max_iter=1000, solver='adam', learning_rate_init=0.001)\n",
    "pipeline = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "\n",
    "param_grid = {\n",
    "    'm__hidden_layer_sizes': [(100,), (50, 50), (50, 100, 50)],  # Size of hidden layers\n",
    "    'm__activation': ['relu', 'tanh', 'logistic'],  # Activation function\n",
    "    # 'm__solver': ['adam', 'sgd'],  # Optimization algorithm\n",
    "    'm__alpha': [0.0001, 0.001, 0.01],  # L2 penalty (regularization term) parameter\n",
    "    'm__learning_rate': ['constant', 'adaptive'],  # Learning rate schedule for weight updates\n",
    "    's__n_features_to_select': [5, 10, 20, 40, 60, 80]  # Number of features to select with RFE\n",
    "}\n",
    "\n",
    "# Inner cross-validation for parameter search\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline, param_grid=param_grid, cv=inner_cv, n_jobs=2\n",
    ")\n",
    "\n",
    "# Outer cross-validation to compute the testing score\n",
    "test_score = cross_val_score(model, X_train_res, y_train_res, cv=outer_cv, n_jobs=2)\n",
    "print(\n",
    "    \"The mean score using nested cross-validation is: \"\n",
    "    f\"{test_score.mean():.3f} Â± {test_score.std():.3f}\"\n",
    ")\n",
    "\n",
    "# Print shape\n",
    "print(X_train_res.shape)\n",
    "print(y_train_res.shape)\n",
    "\n",
    "# Fit model to training data to get best parameters\n",
    "model.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Print best parameters\n",
    "print(model.best_params_)\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = model.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print shape\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# Print classification report \n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate and print the AUC-PR\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]  # Get the probabilities for the positive class\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "auc_pr = auc(recall, precision)\n",
    "print(f\"AUC-PR: {auc_pr:.3f}\")\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "# print(metrics.auc(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "font = 'Times New Roman'\n",
    "size = 18\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Set the style to a modern style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Create a custom diverging color map\n",
    "colors = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=colors, cbar=False,\n",
    "            annot_kws={'fontname': font, 'fontsize': size})  # Set font and size for numbers\n",
    "plt.title('Neural Network', fontname=font, fontsize=size)\n",
    "plt.xlabel('Predicted', fontname=font, fontsize=size)\n",
    "plt.ylabel('Actual', fontname=font, fontsize=size)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "font = 'Times New Roman'\n",
    "size = 18\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Set the style to a modern style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Create a custom diverging color map\n",
    "colors = sns.color_palette(\"Blues\", as_cmap=True)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=colors, cbar=False,\n",
    "            annot_kws={'fontname': font, 'fontsize': size})  # Set font and size for numbers\n",
    "plt.title('Neural Network', fontname=font, fontsize=size)\n",
    "plt.xlabel('Predicted', fontname=font, fontsize=size)\n",
    "plt.ylabel('Actual', fontname=font, fontsize=size)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
