{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest running with only VVR_1 and VVR_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, auc, precision_recall_curve, confusion_matrix\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sum_1', 'Sum_2'], dtype='object')\n",
      "Index(['Sum_1', 'Sum_2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load the data into pandas dataframes\n",
    "X_train_12 = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/X_train_12.csv')\n",
    "y_train_12 = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/y_train_12.csv')\n",
    "X_test_12 = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/X_test_12.csv')\n",
    "y_test = pd.read_csv('/Users/dionnespaltman/Desktop/V6/data_04-06-2024/y_test.csv')\n",
    "\n",
    "X_train_12 = X_train_12.drop(columns='Unnamed: 0', axis=1)\n",
    "y_train_12 = y_train_12.drop(columns='Unnamed: 0', axis=1)\n",
    "X_test_12 = X_test_12.drop(columns='Unnamed: 0', axis=1)\n",
    "y_test = y_test.drop(columns='Unnamed: 0', axis=1)\n",
    "\n",
    "print(X_train_12.columns)\n",
    "print(X_test_12.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_12:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sum_1</th>\n",
       "      <th>Sum_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sum_1  Sum_2\n",
       "0   12.0   13.0\n",
       "1   17.0   16.0\n",
       "2   16.0   12.0\n",
       "3    8.0    8.0\n",
       "4    9.0    8.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_train_12:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VVR_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VVR_group\n",
       "0          1\n",
       "1          1\n",
       "2          1\n",
       "3          0\n",
       "4          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_test_12:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sum_1</th>\n",
       "      <th>Sum_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sum_1  Sum_2\n",
       "0    9.0   11.0\n",
       "1   11.0   10.0\n",
       "2   11.0   10.0\n",
       "3    8.0    8.0\n",
       "4    8.0    8.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "y_test:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VVR_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VVR_group\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the first few rows of each dataframe to verify the loading\n",
    "print(\"X_train_12:\")\n",
    "display(X_train_12.head())\n",
    "\n",
    "print(\"\\ny_train_12:\")\n",
    "display(y_train_12.head())\n",
    "\n",
    "print(\"\\nX_test_12:\")\n",
    "display(X_test_12.head())\n",
    "\n",
    "print(\"\\ny_test:\")\n",
    "# print(y_test)\n",
    "display(y_test.head())\n",
    "\n",
    "# Convert the DataFrame to a 1-dimensional NumPy array\n",
    "y_train_12 = y_train_12.values.ravel()\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with inner and outer split\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean score using nested cross-validation is: 0.699 ± 0.104\n",
      "(77, 2)\n",
      "(77,)\n",
      "{'m__class_weight': None, 'm__max_depth': None, 'm__n_estimators': 100, 's__n_features_to_select': 5}\n",
      "(34,)\n",
      "(34,)\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84        23\n",
      "           1       0.71      0.45      0.56        11\n",
      "\n",
      "    accuracy                           0.76        34\n",
      "   macro avg       0.75      0.68      0.70        34\n",
      "weighted avg       0.76      0.76      0.75        34\n",
      "\n",
      "[[21  2]\n",
      " [ 6  5]]\n",
      "AUC-PR: 0.601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Declare the inner and outer cross-validation strategies\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the pipeline with RFE and the model\n",
    "# rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=2)\n",
    "rfe = RFE(estimator=DecisionTreeClassifier())\n",
    "model = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "\n",
    "param_grid = {\n",
    "    'm__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'm__class_weight': [{0: 0.7549019607843137, 1: 1.4807692307692308}, None],  # Class weights\n",
    "    'm__max_depth': [None, 10, 20],  # Maximum depth of the tree\n",
    "    # 's__n_features_to_select': [5, 20]  # Number of features to select with RFE\n",
    "\n",
    "}\n",
    "\n",
    "# Inner cross-validation for parameter search\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline, param_grid=param_grid, cv=inner_cv, n_jobs=2\n",
    ")\n",
    "\n",
    "# Outer cross-validation to compute the testing score\n",
    "test_score = cross_val_score(model, X_train_12, y_train_12, cv=outer_cv, n_jobs=2)\n",
    "print(\n",
    "    \"The mean score using nested cross-validation is: \"\n",
    "    f\"{test_score.mean():.3f} ± {test_score.std():.3f}\"\n",
    ")\n",
    "\n",
    "# Print shape\n",
    "print(X_train_12.shape)\n",
    "print(y_train_12.shape)\n",
    "\n",
    "# Fit model to training data to get best parameters\n",
    "model.fit(X_train_12, y_train_12)\n",
    "\n",
    "# Print best parameters\n",
    "print(model.best_params_)\n",
    "\n",
    "# Print the features that were selected with RFE\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = model.best_estimator_\n",
    "y_pred = best_model.predict(X_test_12)\n",
    "\n",
    "# Print shape\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# Print classification report \n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate and print the AUC-PR\n",
    "y_proba = best_model.predict_proba(X_test_12)[:, 1]  # Get the probabilities for the positive class\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "auc_pr = auc(recall, precision)\n",
    "print(f\"AUC-PR: {auc_pr:.3f}\")\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "# print(metrics.auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_12: (77, 2)\n",
      "Shape of y_train_12: (77,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of y_train_12:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_train_12\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m# Convert y_train_12 and y_test to pandas Series after raveling them\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m y_train_12 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43my_train_12\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241m.\u001b[39mravel())\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Convert y_test to pandas Series after raveling it\u001b[39;00m\n\u001b[1;32m    109\u001b[0m y_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(y_test\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mravel())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "\n",
    "def build_pipeline():\n",
    "    \"\"\"Builds the machine learning pipeline with RFE and RandomForestClassifier.\"\"\"\n",
    "    rfe = RFE(estimator=DecisionTreeClassifier(random_state=0))\n",
    "    model = RandomForestClassifier(random_state=0)\n",
    "    return Pipeline(steps=[('feature_selection', rfe), ('classifier', model)])\n",
    "\n",
    "def get_param_grid():\n",
    "    \"\"\"Returns the hyperparameter grid for GridSearchCV.\"\"\"\n",
    "    return {\n",
    "        'classifier__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "        'classifier__class_weight': [{0: 0.75, 1: 1.48}, None],  # Class weights\n",
    "        'classifier__max_depth': [None, 10, 20],  # Maximum depth of the tree\n",
    "        'feature_selection__n_features_to_select': [5, 10, 20, 40, 80]  # Number of features to select with RFE\n",
    "    }\n",
    "\n",
    "def perform_nested_cv(X, y, random_state=0):\n",
    "    \"\"\"Performs nested cross-validation and returns the test scores.\"\"\"\n",
    "    inner_cv = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    outer_cv = KFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    pipeline = build_pipeline()\n",
    "    param_grid = get_param_grid()\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=inner_cv, n_jobs=2)\n",
    "    outer_cv_results = []\n",
    "\n",
    "    for train_idx, test_idx in outer_cv.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the scores from the inner cross-validation\n",
    "        inner_cv_results = grid_search.cv_results_['mean_test_score']\n",
    "        inner_cv_std = grid_search.cv_results_['std_test_score']\n",
    "        \n",
    "        outer_cv_results.append((inner_cv_results.mean(), inner_cv_std.mean(), grid_search.best_estimator_))\n",
    "    \n",
    "    outer_cv_means = [result[0] for result in outer_cv_results]\n",
    "    outer_cv_stds = [result[1] for result in outer_cv_results]\n",
    "    \n",
    "    print(f\"Mean scores for each outer fold: {outer_cv_means}\")\n",
    "    print(f\"Standard deviation for each outer fold: {outer_cv_stds}\")\n",
    "    print(f\"The overall mean score using nested cross-validation is: {np.mean(outer_cv_means):.3f} ± {np.std(outer_cv_means):.3f}\")\n",
    "    \n",
    "    return outer_cv_results\n",
    "\n",
    "def plot_curves(y_test, y_proba, y_pred):\n",
    "    \"\"\"Plots PR and ROC curves.\"\"\"\n",
    "    # Plot Precision-Recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    plt.figure()\n",
    "    plt.plot(recall, precision, label=f'Precision-Recall curve (AUC = {auc_pr:.3f})')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC curve (AUC = {auc_roc:.3f})')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(best_model, X_test, y_test):\n",
    "    \"\"\"Evaluates the best model on the test set and plots the curves.\"\"\"\n",
    "    print(\"\\nEvaluating best model on test set\")\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    \n",
    "    print(\"\\nClassification Report on Test Set:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    \n",
    "    y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "    plot_curves(y_test, y_test_proba, y_test_pred)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_test_proba)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    print(f\"Test AUC-PR: {auc_pr:.3f}\")\n",
    "\n",
    "# Example usage with your data\n",
    "random_seed = 42\n",
    "\n",
    "# Print the shape of your training and test data\n",
    "print(\"Shape of X_train_12:\", X_train_12.shape)\n",
    "print(\"Shape of y_train_12:\", y_train_12.shape)\n",
    "\n",
    "# Convert y_train_12 and y_test to pandas Series after raveling them\n",
    "y_train_12 = pd.Series(y_train_12.values.ravel())\n",
    "\n",
    "# Convert y_test to pandas Series after raveling it\n",
    "y_test = pd.Series(y_test.values.ravel())\n",
    "\n",
    "print(\"Shape of X_test_12:\", X_test_12.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "cv_results = perform_nested_cv(X_train_12, y_train_12, random_state=random_seed)\n",
    "\n",
    "# Use the best model from the cross-validation for evaluation on the test set\n",
    "best_model = max(cv_results, key=lambda x: x[0])[2]\n",
    "\n",
    "evaluate_model(best_model, X_test_12, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [30, 34]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m18\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate confusion matrix\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Set the style to a modern style\u001b[39;00m\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn-darkgrid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:319\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    225\u001b[0m     {\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [30, 34]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "font = 'Times New Roman'\n",
    "size = 18\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Set the style to a modern style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Create a custom diverging color map\n",
    "colors = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=colors, cbar=False,\n",
    "            annot_kws={'fontname': font, 'fontsize': size})  # Set font and size for numbers\n",
    "plt.title('Random Forest', fontname=font, fontsize=size)\n",
    "plt.xlabel('Predicted', fontname=font, fontsize=size)\n",
    "plt.ylabel('Actual', fontname=font, fontsize=size)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
