{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost running with only VVR_1 and VVR_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add description. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, auc, precision_recall_curve, confusion_matrix\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into pandas dataframes\n",
    "X_train_12 = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/X_train_12.csv')\n",
    "y_train_12 = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/y_train_12.csv')\n",
    "X_test_12 = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/X_test_12.csv')\n",
    "y_test = pd.read_csv('/Users/dionnespaltman/Desktop/V4/data/y_test.csv')\n",
    "\n",
    "X_train_12 = X_train_12.drop(columns='Unnamed: 0', axis=1)\n",
    "y_train_12 = y_train_12.drop(columns='Unnamed: 0', axis=1)\n",
    "X_test_12 = X_test_12.drop(columns='Unnamed: 0', axis=1)\n",
    "y_test = y_test.drop(columns='Unnamed: 0', axis=1)\n",
    "\n",
    "# # Display the first few rows of each dataframe to verify the loading\n",
    "# print(\"X_train_12:\")\n",
    "# display(X_train_12.head())\n",
    "\n",
    "# print(\"\\ny_train_12:\")\n",
    "# display(y_train_12.head())\n",
    "\n",
    "# print(\"\\nX_test_12:\")\n",
    "# display(X_test_12.head())\n",
    "\n",
    "# print(\"\\ny_test:\")\n",
    "# # print(y_test)\n",
    "# display(y_test.head())\n",
    "\n",
    "# Convert the DataFrame to a 1-dimensional NumPy array\n",
    "y_train_12 = y_train_12.values.ravel()\n",
    "y_test = y_test.values.ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with inner and outer split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean score using nested cross-validation is: 0.806 ± 0.039\n",
      "(72, 2)\n",
      "(72,)\n",
      "{'m__learning_rate': 0.01, 'm__max_depth': 3, 'm__min_child_weight': 1, 'm__n_estimators': 100, 's__n_features_to_select': 5}\n",
      "(32,)\n",
      "(32,)\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92        25\n",
      "           1       0.80      0.57      0.67         7\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.84      0.77      0.79        32\n",
      "weighted avg       0.87      0.88      0.87        32\n",
      "\n",
      "[[24  1]\n",
      " [ 3  4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Declare the inner and outer cross-validation strategies\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# Create the pipeline with RFE and the model\n",
    "# rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=2)\n",
    "rfe = RFE(estimator=DecisionTreeClassifier())\n",
    "model = XGBClassifier()\n",
    "pipeline = Pipeline(steps=[('s', rfe), ('m', model)])\n",
    "\n",
    "param_grid = {\n",
    "    'm__learning_rate': [0.1, 0.01],  # Learning rate\n",
    "    'm__n_estimators': [50, 100, 200],  # Number of trees\n",
    "    'm__max_depth': [3, 5, 8],  # Maximum depth of a tree\n",
    "    'm__min_child_weight': [1, 5],  # Minimum sum of instance weight needed in a child\n",
    "    's__n_features_to_select': [5, 10, 15, 20]  # Number of features to select with RFE\n",
    "}\n",
    "\n",
    "# Inner cross-validation for parameter search\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline, param_grid=param_grid, cv=inner_cv, n_jobs=2\n",
    ")\n",
    "\n",
    "# Outer cross-validation to compute the testing score\n",
    "test_score = cross_val_score(model, X_train_12, y_train_12, cv=outer_cv, n_jobs=2)\n",
    "print(\n",
    "    \"The mean score using nested cross-validation is: \"\n",
    "    f\"{test_score.mean():.3f} ± {test_score.std():.3f}\"\n",
    ")\n",
    "\n",
    "# Print shape\n",
    "print(X_train_12.shape)\n",
    "print(y_train_12.shape)\n",
    "\n",
    "# Fit model to training data to get best parameters\n",
    "model.fit(X_train_12, y_train_12)\n",
    "\n",
    "# Print best parameters\n",
    "print(model.best_params_)\n",
    "\n",
    "# Print the features that were selected with RFE\n",
    "\n",
    "# Evaluate on the test set\n",
    "best_model = model.best_estimator_\n",
    "y_pred = best_model.predict(X_test_12)\n",
    "\n",
    "# Print shape\n",
    "print(y_test.shape)\n",
    "print(y_pred.shape)\n",
    "\n",
    "# Print classification report \n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Calculate and print the AUC-PR\n",
    "y_proba = best_model.predict_proba(X_test_12)[:, 1]  # Get the probabilities for the positive class\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "auc_pr = auc(recall, precision)\n",
    "print(f\"AUC-PR: {auc_pr:.3f}\")\n",
    "\n",
    "\n",
    "# fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=2)\n",
    "# print(metrics.auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "font = 'Times New Roman'\n",
    "size = 18\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Set the style to a modern style\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Create a custom diverging color map\n",
    "colors = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=colors, cbar=False,\n",
    "            annot_kws={'fontname': font, 'fontsize': size})  # Set font and size for numbers\n",
    "plt.title('XGBoost - features VVR_1 and VVR_2', fontname=font, fontsize=size)\n",
    "plt.xlabel('Predicted', fontname=font, fontsize=size)\n",
    "plt.ylabel('Actual', fontname=font, fontsize=size)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
