{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, auc, precision_recall_curve, confusion_matrix\n",
    "import pandas as pd\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_csv('/Users/dionnespaltman/Desktop/V3/merged_df.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(merged_df, test_size=0.2, random_state=123)\n",
    "train, val = train_test_split(train, stratify=train['VVR_group'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/dionnespaltman/Desktop/V3/columns_action_units.json', 'r') as f:\n",
    "    columns_action_units = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define featurizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_column_names = columns_action_units\n",
    "featurizer = ColumnTransformer(transformers=[(\"numeric\", StandardScaler(), numerical_column_names)], remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = make_pipeline(featurizer, DummyClassifier(strategy='most_frequent'))\n",
    "rf = make_pipeline(featurizer, RandomForestClassifier())\n",
    "svm = make_pipeline(featurizer, SVC())\n",
    "multiclass_svm = make_pipeline(featurizer, SVC(decision_function_shape='ovr'))\n",
    "xgb = make_pipeline(featurizer, XGBClassifier())\n",
    "mlp = make_pipeline(featurizer, MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000))\n",
    "\n",
    "models = {\n",
    "    \"Dummy\": dummy,\n",
    "    \"RandomForest\": rf,\n",
    "    \"SVM\": svm,\n",
    "    \"Multiclass SVM\": multiclass_svm,\n",
    "    \"XGBoost\": xgb,\n",
    "    \"MLP\": mlp\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance\n",
    "    \"\"\"\n",
    "    model.fit(X, y)\n",
    "    y_probs = model.predict_proba(X)[:, 1]\n",
    "    precision = precision_score(y, model.predict(X))\n",
    "    recall = recall_score(y, model.predict(X))\n",
    "    f1 = f1_score(y, model.predict(X))\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y, y_probs)\n",
    "    auc_pr = auc(recall_curve, precision_curve)\n",
    "    cm = confusion_matrix(y, model.predict(X))\n",
    "    \n",
    "    logging.info(f\"Precision: {precision}\")\n",
    "    logging.info(f\"Recall: {recall}\")\n",
    "    logging.info(f\"F1-score: {f1}\")\n",
    "    logging.info(f\"AUC-PR score: {auc_pr}\")\n",
    "    logging.info(f\"Confusion Matrix:\")\n",
    "    logging.info(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fitting models\n",
      "INFO:root:Evaluating Dummy on validation data\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/dionnespaltman/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "INFO:root:Dummy Accuracy: 0.7727272727272727\n",
      "INFO:root:Dummy Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        17\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.77        22\n",
      "   macro avg       0.39      0.50      0.44        22\n",
      "weighted avg       0.60      0.77      0.67        22\n",
      "\n",
      "INFO:root:Dummy Confusion Matrix:\n",
      "INFO:root:[[17  0]\n",
      " [ 5  0]]\n",
      "INFO:root:Evaluating RandomForest on validation data\n",
      "INFO:root:RandomForest Accuracy: 0.6363636363636364\n",
      "INFO:root:RandomForest Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78        17\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.37      0.41      0.39        22\n",
      "weighted avg       0.57      0.64      0.60        22\n",
      "\n",
      "INFO:root:RandomForest Confusion Matrix:\n",
      "INFO:root:[[14  3]\n",
      " [ 5  0]]\n",
      "INFO:root:Evaluating SVM on validation data\n",
      "INFO:root:SVM Accuracy: 0.6818181818181818\n",
      "INFO:root:SVM Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81        17\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.38      0.44      0.41        22\n",
      "weighted avg       0.58      0.68      0.63        22\n",
      "\n",
      "INFO:root:SVM Confusion Matrix:\n",
      "INFO:root:[[15  2]\n",
      " [ 5  0]]\n",
      "INFO:root:Evaluating Multiclass SVM on validation data\n",
      "INFO:root:Multiclass SVM Accuracy: 0.6818181818181818\n",
      "INFO:root:Multiclass SVM Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81        17\n",
      "           1       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.68        22\n",
      "   macro avg       0.38      0.44      0.41        22\n",
      "weighted avg       0.58      0.68      0.63        22\n",
      "\n",
      "INFO:root:Multiclass SVM Confusion Matrix:\n",
      "INFO:root:[[15  2]\n",
      " [ 5  0]]\n",
      "INFO:root:Evaluating XGBoost on validation data\n",
      "INFO:root:XGBoost Accuracy: 0.8181818181818182\n",
      "INFO:root:XGBoost Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        17\n",
      "           1       0.67      0.40      0.50         5\n",
      "\n",
      "    accuracy                           0.82        22\n",
      "   macro avg       0.75      0.67      0.69        22\n",
      "weighted avg       0.80      0.82      0.80        22\n",
      "\n",
      "INFO:root:XGBoost Confusion Matrix:\n",
      "INFO:root:[[16  1]\n",
      " [ 3  2]]\n",
      "INFO:root:Evaluating MLP on validation data\n",
      "INFO:root:MLP Accuracy: 0.5454545454545454\n",
      "INFO:root:MLP Classification Report:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69        17\n",
      "           1       0.14      0.20      0.17         5\n",
      "\n",
      "    accuracy                           0.55        22\n",
      "   macro avg       0.44      0.42      0.43        22\n",
      "weighted avg       0.60      0.55      0.57        22\n",
      "\n",
      "INFO:root:MLP Confusion Matrix:\n",
      "INFO:root:[[11  6]\n",
      " [ 4  1]]\n",
      "INFO:root:Predicting on test using XGBoost\n",
      "INFO:root:XGBoost Accuracy on Test Data: 0.782608695652174\n",
      "INFO:root:XGBoost Classification Report on Test Data:\n",
      "INFO:root:              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        19\n",
      "           1       0.33      0.25      0.29         4\n",
      "\n",
      "    accuracy                           0.78        23\n",
      "   macro avg       0.59      0.57      0.58        23\n",
      "weighted avg       0.76      0.78      0.77        23\n",
      "\n",
      "INFO:root:XGBoost Confusion Matrix:\n",
      "INFO:root:[[17  2]\n",
      " [ 3  1]]\n",
      "INFO:root:Precision: 1.0\n",
      "INFO:root:Recall: 1.0\n",
      "INFO:root:F1-score: 1.0\n",
      "INFO:root:AUC-PR score: 1.0\n",
      "INFO:root:Confusion Matrix:\n",
      "INFO:root:[[19  0]\n",
      " [ 0  4]]\n"
     ]
    }
   ],
   "source": [
    "# Set logging level to INFO\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "# merged_df = load_data()\n",
    "# train, val, test = split_data(merged_df)\n",
    "# columns_action_units = load_columns()\n",
    "# featurizer = define_featurizer(columns_action_units)\n",
    "# models = define_models(featurizer)\n",
    "\n",
    "logging.info(\"Fitting models\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(train.drop('VVR_group', axis=1), train['VVR_group'].values)\n",
    "    logging.info(f\"Evaluating {name} on validation data\")\n",
    "    pred = model.predict(val.drop('VVR_group', axis=1))\n",
    "    accuracy = accuracy_score(val['VVR_group'].values, pred)\n",
    "    report = classification_report(val['VVR_group'].values, pred)\n",
    "    cm = confusion_matrix(val['VVR_group'].values, pred)\n",
    "    \n",
    "    logging.info(f\"{name} Accuracy: {accuracy}\")\n",
    "    logging.info(f\"{name} Classification Report:\")\n",
    "    logging.info(report)\n",
    "    logging.info(f\"{name} Confusion Matrix:\")\n",
    "    logging.info(cm)\n",
    "\n",
    "best_model_name = max(models, key=lambda x: accuracy_score(val['VVR_group'].values, models[x].predict(val.drop('VVR_group', axis=1))))\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "logging.info(f\"Predicting on test using {best_model_name}\")\n",
    "\n",
    "pred = best_model.predict(test.drop('VVR_group', axis=1))\n",
    "\n",
    "accuracy = accuracy_score(test['VVR_group'].values, pred)\n",
    "report = classification_report(test['VVR_group'].values, pred)\n",
    "cm = confusion_matrix(test['VVR_group'].values, pred)\n",
    "\n",
    "logging.info(f\"{best_model_name} Accuracy on Test Data: {accuracy}\")\n",
    "logging.info(f\"{best_model_name} Classification Report on Test Data:\")\n",
    "logging.info(report)\n",
    "logging.info(f\"{best_model_name} Confusion Matrix:\")\n",
    "logging.info(cm)\n",
    "\n",
    "evaluate_model(best_model, test.drop('VVR_group', axis=1), test['VVR_group'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
